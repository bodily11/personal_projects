{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "58e0db8a95cf9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "#import the lti_context_id to root_guid_id report\n",
    "guid_to_context = pd.read_csv('lti_context_to_outcome_guid.csv',encoding='utf-8')\n",
    "guid_to_context = guid_to_context[['RootOutcomeGuid','LtiContextId']]   #I only need these two columns so I get rid of the rest\n",
    "guid_to_context.index = guid_to_context.LtiContextId   #assign LtiContextId as the index (to easily match values)\n",
    "\n",
    "df = pd.read_csv('Spring_Assessment_Data.csv')\n",
    "summative = df[df.quiz_type == 'summative']   #only select summative questions\n",
    "summative = summative[summative.attempt == 0]   #only keep first attempt for each student\n",
    "summative['outquest_map'] = summative.outcome_guid.astype(str) + ':' + summative.question_id.astype(str)\n",
    "outquest_to_id_default = pd.DataFrame(pd.Series(range(len(summative.outquest_map.unique()))).astype(str).values,index=summative.outquest_map.unique(),columns=['id'])\n",
    "summative['outquest'] = summative['outquest_map'].map(lambda x: outquest_to_id_default.loc[x,'id'])   #assigns a new id to each question attempt record\n",
    "def get_root_guid(cell):\n",
    "    if cell != cell:   #handles None or missing values\n",
    "        return None\n",
    "    else:\n",
    "        if str(cell) in guid_to_context.index:   #checks if the LtiContextId is located in the mapping file\n",
    "            result = guid_to_context.loc[str(cell),'RootOutcomeGuid']   #gets the RootOutcomeGuid\n",
    "            if type(result) == float:   #handles float values\n",
    "                result = str(result)\n",
    "            if len(result) == 2:   #handles list values\n",
    "                try:\n",
    "                    cell_guid = result[0]\n",
    "                except:\n",
    "                    return None\n",
    "            else:                \n",
    "                cell_guid = str(result)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    return cell_guid\n",
    "\n",
    "#run the get_root_guid function to get RootOutcomeGuid from Lti_Context_Id\n",
    "summative['root_guid'] = summative['lti_context_id'].map(get_root_guid)\n",
    "\n",
    "#read in the all-outcomes text file\n",
    "outcomes1_txt = open('outcomes.txt')\n",
    "outcomes1_str = outcomes1_txt.read()\n",
    "outcomes1_json = json.loads(outcomes1_str)\n",
    "outcomes1 = pd.DataFrame(outcomes1_json)\n",
    "\n",
    "courses_df = outcomes1[outcomes1.root_guid != outcomes1.root_guid]\n",
    "\n",
    "dfBus = pd.read_csv('Introduction to Business_c948_final_IRT-CFA_data.csv')\n",
    "dfMac = pd.read_csv('Macroeconomics _32d6_final_IRT-CFA_data.csv')\n",
    "dfMic = pd.read_csv('Microeconomics _ec9a_final_IRT-CFA_data.csv')\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "comet_cell_id": "4dd2c8d44bb63"
   },
   "outputs": [],
   "source": [
    "dfBus_outcomes = dfBus[dfBus.model_fit < 3].outcome.unique()\n",
    "dfMac_outcomes = dfMac[dfMac.model_fit < 3].outcome.unique()\n",
    "dfMic_outcomes = dfMic[dfMic.model_fit < 3].outcome.unique()\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "5082668c04892"
   },
   "outputs": [],
   "source": [
    "dfBusOutcomes = pd.read_csv('Introduction to Business_c948_no_converge_outcomes.csv')\n",
    "dfBusOutcomes = dfBusOutcomes.outcome.values\n",
    "dfMacOutcomes = pd.read_csv('Macroeconomics _32d6_no_converge_outcomes.csv')\n",
    "dfMacOutcomes = dfMacOutcomes.outcome.values\n",
    "dfMicOutcomes = pd.read_csv('Microeconomics _ec9a_no_converge_outcomes.csv')\n",
    "dfMicOutcomes = dfMicOutcomes.outcome.values\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "comet_cell_id": "c6eb007d84384"
   },
   "outputs": [],
   "source": [
    "business_outcomes = list(dfBus_outcomes) + list(dfBusOutcomes)\n",
    "macro_outcomes = list(dfMac_outcomes) + list(dfMacOutcomes)\n",
    "micro_outcomes = list(dfMic_outcomes) + list(dfMicOutcomes)\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "comet_cell_id": "8bd8e6cb4a25a"
   },
   "outputs": [],
   "source": [
    "# efa_trial_outcomes = dfBus[dfBus.model_fit == 1].outcome.value_counts().index[:3]\n",
    "# outcome = efa_trial_outcomes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "comet_cell_id": "141cab20d053f"
   },
   "outputs": [],
   "source": [
    "#extract root_guid and course name\n",
    "from subprocess import call\n",
    "\n",
    "root_guid = courses_df.guid.values[4]\n",
    "course_name = courses_df.short_title.values[4]\n",
    "\n",
    "problem_didnt_run = []\n",
    "it_totally_ran = []\n",
    "results = []\n",
    "\n",
    "for outcome in macro_outcomes:\n",
    "    \n",
    "    pivot_table = summative[(summative.outcome_guid == outcome)&(summative.root_guid == root_guid)].pivot_table(index='lti_user_id', columns='outquest', values='score')\n",
    "    \n",
    "    #remove questions with less than 100 responses\n",
    "    response_threshold = 100\n",
    "    question_count = pivot_table.count()\n",
    "    greater_than_100_questions = question_count[question_count.values > response_threshold].index\n",
    "    pivot_table = pivot_table[greater_than_100_questions]\n",
    "    \n",
    "    #make sure there are enough responses per student (need at least one or two I think)\n",
    "    pivot_table = pivot_table.dropna(axis=0,thresh=1)\n",
    "    pivot_table.fillna(-999,inplace=True)\n",
    "    \n",
    "    for x in pivot_table.columns:\n",
    "        pivot_table.rename(columns={x:\"A\"+str(x)},inplace=True)\n",
    "\n",
    "    pivot_table.to_csv('{}.csv'.format(outcome),header=False,index=False)\n",
    "    \n",
    "    variables = '\\n    '.join(pivot_table.columns)\n",
    "    input_file_name = '{}.inp'.format(outcome)\n",
    "    with open(\"{}\".format(input_file_name), \"w\") as text_file:\n",
    "        text_file.write('''\n",
    "\n",
    "DATA:\n",
    "  FILE IS {}.csv;\n",
    "\n",
    "VARIABLE:\n",
    "\n",
    "  NAMES ARE\n",
    "  {}\n",
    "  ;\n",
    "\n",
    "  USEVARIABLES ARE\n",
    "  {}\n",
    "  ;\n",
    "\n",
    "  MISSING ARE ALL (-999);\n",
    "\n",
    "ANALYSIS:\n",
    "    TYPE = efa 1 3;\n",
    "    COVERAGE = 0.001;\n",
    "    ROTATION = varimax;\n",
    "\n",
    "PLOT: TYPE = PLOT2;\n",
    "\n",
    "!CFA code\n",
    "!MODEL:\n",
    "!outcome by a1003\n",
    "!a1034\n",
    "!a705\n",
    "!a825\n",
    "!a844;\n",
    "'''.format(outcome, variables, variables))\n",
    "                        \n",
    "    output_file_name = '{}.out'.format(outcome)\n",
    "    store = call(['mplus','{}'.format(input_file_name),'{}'.format(output_file_name)])\n",
    "    if store == 1:\n",
    "        problem_didnt_run.append(outcome)\n",
    "        continue\n",
    "    else:\n",
    "        it_totally_ran.append(outcome)\n",
    "    \n",
    "    with open('{}'.format(output_file_name), 'r') as f:\n",
    "        string = f.readlines()\n",
    "    \n",
    "    output = ''\n",
    "    for line in string:\n",
    "        output += line\n",
    "    ##\n",
    "\n",
    "    def get_number_out(string,starta,enda,startb,endb):\n",
    "        l = re.search(starta,string)\n",
    "        start1 = l.start(0)\n",
    "        m = re.search(enda,string[start1:])\n",
    "        end1 = m.start(0) + start1 + 3\n",
    "        string2 = string[start1:end1]\n",
    "\n",
    "        n = re.search(startb,string2)\n",
    "        start2 = n.start(0)\n",
    "        o = re.search(endb,string2[start2:])\n",
    "        end2 = o.start(0) + start2\n",
    "        final_string = string2[start2:end2]\n",
    "        return final_string\n",
    "    ##\n",
    "\n",
    "    import re\n",
    "    output2 = output[output.find('SUMMARY OF MODEL FIT INFORMATION'):]\n",
    "    try:\n",
    "        factor_one_results = get_number_out(output,'1-factor','\\n','[0-9][0-9]','\\n')\n",
    "        factor_one_results = pd.Series(factor_one_results.split(' '))\n",
    "        factor_one_results = factor_one_results[factor_one_results != ''].values\n",
    "    except:\n",
    "        factor_one_results = None\n",
    "\n",
    "    try:\n",
    "        factor_two_results = get_number_out(output,'2-factor','\\n','[0-9][0-9]','\\n')\n",
    "        factor_two_results = pd.Series(factor_two_results.split(' '))\n",
    "        factor_two_results = factor_two_results[factor_two_results != ''].values\n",
    "    except:\n",
    "        factor_two_results = None\n",
    "\n",
    "    try:\n",
    "        factor_three_results = get_number_out(output,'3-factor','\\n','[0-9][0-9]','\\n')\n",
    "        factor_three_results = pd.Series(factor_three_results.split(' '))\n",
    "        factor_three_results = factor_three_results[factor_three_results != ''].values\n",
    "    except:\n",
    "        factor_three_results = None\n",
    "    ##\n",
    "\n",
    "    #this might not work if two models both work. I'll need to test that.\n",
    "    if 'EXPLORATORY FACTOR ANALYSIS WITH 1 FACTOR(S):' in output:\n",
    "        output2 = output[output.find('EXPLORATORY FACTOR ANALYSIS WITH 1 FACTOR(S):'):]\n",
    "        output2 = output2[output2.find('ESTIMATED FACTOR LOADINGS'):]\n",
    "        factor_loadings = []\n",
    "        for x in range(len(pivot_table.columns)):\n",
    "            if x == -1:\n",
    "                factor_loadings.append(get_number_out(output2,'ESTIMATED FACTOR LOADINGS',pivot_table.columns[1],'[0-9]\\.[0-9]','\\n'))\n",
    "            elif x == len(pivot_table.columns) - 1:\n",
    "                factor_loadings.append(get_number_out(output2,pivot_table.columns[x],'ESTIMATED RESIDUAL VARIANCES','[0-9]\\.[0-9]','\\n'))\n",
    "            else:\n",
    "                factor_loadings.append(get_number_out(output2,pivot_table.columns[x],pivot_table.columns[x+1],'[0-9]\\.[0-9]','\\n'))\n",
    "        factor1df = pd.DataFrame(zip(pivot_table.columns,factor_loadings))\n",
    "    else:\n",
    "        factor1df = None\n",
    "    ##\n",
    "\n",
    "    #parse the factor two results if there are results\n",
    "    if 'EXPLORATORY FACTOR ANALYSIS WITH 2 FACTOR(S):' in output:\n",
    "        output2 = output[output.find('EXPLORATORY FACTOR ANALYSIS WITH 2 FACTOR(S):'):]\n",
    "        output2 = output2[output2.find('VARIMAX ROTATED LOADINGS'):]\n",
    "        factor_loadings1 = []\n",
    "        factor_loadings2 = []\n",
    "        for x in range(len(pivot_table.columns)):\n",
    "            if x == -1:\n",
    "                loadings = get_number_out(output2,'VARIMAX ROTATED LOADINGS',pivot_table.columns[1],'[0-9]\\.[0-9]','\\n').split(' ')\n",
    "                loadings2 = []\n",
    "                for y in loadings:\n",
    "                    if y == '':\n",
    "                        pass\n",
    "                    else:\n",
    "                        loadings2.append(y)\n",
    "                factor_loadings1.append(loadings2[0])\n",
    "                factor_loadings2.append(loadings2[1])\n",
    "            elif x == len(pivot_table.columns) - 1:\n",
    "                loadings = get_number_out(output2,pivot_table.columns[x],'ESTIMATED RESIDUAL VARIANCES','[0-9]\\.[0-9]','\\n').split(' ')\n",
    "                loadings2 = []\n",
    "                for y in loadings:\n",
    "                    if y == '':\n",
    "                        pass\n",
    "                    else:\n",
    "                        loadings2.append(y)\n",
    "                factor_loadings1.append(loadings2[0])\n",
    "                factor_loadings2.append(loadings2[1])\n",
    "            else:\n",
    "                loadings = get_number_out(output2,pivot_table.columns[x],pivot_table.columns[x+1],'[0-9]\\.[0-9]','\\n').split(' ')\n",
    "                loadings2 = []\n",
    "                for y in loadings:\n",
    "                    if y == '':\n",
    "                        pass\n",
    "                    else:\n",
    "                        loadings2.append(y)\n",
    "                factor_loadings1.append(loadings2[0])\n",
    "                factor_loadings2.append(loadings2[1])\n",
    "        factor2df = pd.DataFrame(zip(pivot_table.columns,factor_loadings1,factor_loadings2))\n",
    "    else:\n",
    "        factor2df = None\n",
    "    ##\n",
    "\n",
    "    #parse the factor three results if there are results\n",
    "    if 'EXPLORATORY FACTOR ANALYSIS WITH 3 FACTOR(S):' in output:\n",
    "        output2 = output[output.find('EXPLORATORY FACTOR ANALYSIS WITH 3 FACTOR(S):'):]\n",
    "        output2 = output2[output2.find('VARIMAX ROTATED LOADINGS'):]\n",
    "        factor_loadings1 = []\n",
    "        factor_loadings2 = []\n",
    "        factor_loadings3 = []\n",
    "        for x in range(len(pivot_table.columns)):\n",
    "            if x == -1:\n",
    "                loadings = get_number_out(output2,'VARIMAX ROTATED LOADINGS',pivot_table.columns[1],'[0-9]\\.[0-9]','\\n').split(' ')\n",
    "                loadings2 = []\n",
    "                for y in loadings:\n",
    "                    if y == '':\n",
    "                        pass\n",
    "                    else:\n",
    "                        loadings2.append(y)\n",
    "                factor_loadings1.append(loadings2[0])\n",
    "                factor_loadings2.append(loadings2[1])\n",
    "                factor_loadings3.append(loadings2[2])\n",
    "            elif x == len(pivot_table.columns) - 1:\n",
    "                loadings = get_number_out(output2,pivot_table.columns[x],'ESTIMATED RESIDUAL VARIANCES','[0-9]\\.[0-9]','\\n').split(' ')\n",
    "                loadings2 = []\n",
    "                for y in loadings:\n",
    "                    if y == '':\n",
    "                        pass\n",
    "                    else:\n",
    "                        loadings2.append(y)\n",
    "                factor_loadings1.append(loadings2[0])\n",
    "                factor_loadings2.append(loadings2[1])\n",
    "                factor_loadings3.append(loadings2[2])\n",
    "            else:\n",
    "                loadings = get_number_out(output2,pivot_table.columns[x],pivot_table.columns[x+1],'[0-9]\\.[0-9]','\\n').split(' ')\n",
    "                loadings2 = []\n",
    "                for y in loadings:\n",
    "                    if y == '':\n",
    "                        pass\n",
    "                    else:\n",
    "                        loadings2.append(y)\n",
    "                factor_loadings1.append(loadings2[0])\n",
    "                factor_loadings2.append(loadings2[1])\n",
    "                factor_loadings3.append(loadings2[2])\n",
    "        factor3df = pd.DataFrame(zip(pivot_table.columns,factor_loadings1,factor_loadings2,factor_loadings3))\n",
    "    else:\n",
    "        factor3df = None\n",
    "    ##\n",
    "\n",
    "    results.append({\n",
    "        'Outcome':outcome,\n",
    "        '1FactorResults':factor_one_results,\n",
    "        '1FactorLoadings':factor1df,\n",
    "        '2FactorResults':factor_two_results,\n",
    "        '2FactorLoadings':factor2df,\n",
    "        '3FactorResults':factor_three_results,\n",
    "        '3FactorLoadings':factor3df\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "dfMac_fit = dfMac[['outcome','short_title','model_fit']].copy()\n",
    "dfMac_fit.drop_duplicates(inplace=True)\n",
    "dfMac_fit.rename(columns={'outcome':'Outcome'},inplace=True)\n",
    "dfMac_fit = dfMac_fit[dfMac_fit.model_fit < 3]\n",
    "\n",
    "df = df.merge(dfMac_fit,on='Outcome',how='outer')\n",
    "\n",
    "df.to_csv('{}_EFA_Results.csv'.format(course_name),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "67d8cbbb03c8e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "76d2e5bfe744f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "6f10853afecdc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "a1a9ae8f1079d"
   },
   "outputs": [],
   "source": [
    "tarah_outcomes = dfMac[dfMac.parent_outcome == '479cce89-e456-4fa0-9bc0-debe586390ac'].outcome.unique()\n",
    "\n",
    "test = summative[(summative.outcome_guid.isin(tarah_outcomes))&(summative.root_guid == '32d69033-0515-4d54-b615-c05e74f88bf5')]\n",
    "\n",
    "for outcome in test.outcome_guid:\n",
    "    test_df = test[test.outcome_guid == outcome]\n",
    "    final_data = test_df.pivot_table(index='lti_user_id', columns='outquest', values='score')\n",
    "    final_data.to_csv('{}_TBKIkahihifo.csv'.format(outcome),index=False)\n",
    "    \n",
    "\n",
    "dfMac.groupby('parent_outcome').sum()"
   ]
  }
 ],
 "metadata": {
  "comet_paths": [],
  "comet_tracking": true,
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
