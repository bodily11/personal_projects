{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "comet_cell_id": "46db794561816"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import math\n",
    "import sys\n",
    "from scipy.stats.stats import pearsonr\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import ttest_ind as ttest\n",
    "\n",
    "#start timer\n",
    "start = time.time()\n",
    "\n",
    "avgbetas = [0,1]\n",
    "cov_changes = [(0,0),(1,0),(1,-1)]\n",
    "group_comparisons = 1\n",
    "sample_sizes = [1000,5000,10000,21754]\n",
    "number_of_simulations = sys.argv[1]\n",
    "stratify_level = 5\n",
    "cov_elims = [0,1]\n",
    "groups = [(0,1),(1,2),(1,3),(0,2),(0,3),(2,3)]\n",
    "\n",
    "p1 = [.1378,.25,.15,.1]\n",
    "p2 = [.0536,.25,.15,.1]\n",
    "p3 = [.0647,.25,.2,.4]\n",
    "p4 = [.744,.25,.5,.4]\n",
    "#############################\n",
    "#analyses to run\n",
    "#X'simple_mean_difference'\n",
    "#X'linear_regression'\n",
    "#X'simple_covariate_split_stratification'\n",
    "#X'stratify_propensities_5'\n",
    "#X'stratify_propensities_10'\n",
    "#X'stratify_propensities_20'\n",
    "#X'weight_inverse_regression_5'\n",
    "#X'weight_inverse_regression_10'\n",
    "#X'weight_inverse_regression_20'\n",
    "#############################\n",
    "\n",
    "\n",
    "\n",
    "for z in range(int(number_of_simulations)):\n",
    "    corr_diff = []\n",
    "    final_effect_sizes = []\n",
    "    for pgroup in range(group_comparisons):\n",
    "        for N in sample_sizes:\n",
    "            N = int(N*1.25)\n",
    "            k = int(p1[pgroup]*N)\n",
    "            l = int(p2[pgroup]*N)\n",
    "            m = int(p3[pgroup]*N)\n",
    "            n = int(p4[pgroup]*N)\n",
    "            cor12 = np.corrcoef([1] * k + [0] * (N-k),[0] * (N-l) + [1] * l)[0][1]\n",
    "            cor13 = np.corrcoef([1] * k + [0] * (N-k),[0] * (N-m) + [1] * m)[0][1]\n",
    "            cor14 = np.corrcoef([1] * k + [0] * (N-k),[0] * (N-n) + [1] * n)[0][1]\n",
    "            cor23 = np.corrcoef([1] * l + [0] * (N-l),[0] * (N-m) + [1] * m)[0][1]\n",
    "            cor24 = np.corrcoef([1] * l + [0] * (N-l),[0] * (N-n) + [1] * n)[0][1]\n",
    "            cor34 = np.corrcoef([1] * m + [0] * (N-m),[0] * (N-n) + [1] * n)[0][1]\n",
    "\n",
    "            #specify means for your 5 continuous variables\n",
    "            mean = (0,0,0,0,0)\n",
    "\n",
    "            #specify the covariance matrix for your 5 continuous variables\n",
    "            cov = [(1,-.204,.075,-.054,-.015),\n",
    "                    (-.204,1,-.106,.123,.068),\n",
    "                    (.075,-.106,1,-.821,-.069),\n",
    "                    (-.054,.123,-.821,1,.079),\n",
    "                    (-.015,.068,-.069,.079,1)]\n",
    "\n",
    "\n",
    "            #simulate the continuous data from a multivariate normal distribution\n",
    "            v1,v2,v3,v4,v5 = np.random.multivariate_normal(mean,cov,N).T\n",
    "\n",
    "            #save values in a dataframe\n",
    "            index = range(N)\n",
    "            columns = ['v1','v2','v3','v4','v5']\n",
    "            df = pd.DataFrame(\n",
    "                {'v1': v1,\n",
    "                 'v2': v2,\n",
    "                 'v3': v3,\n",
    "                 'v4': v4,\n",
    "                 'v5': v5}, index=index, columns=columns)\n",
    "            #create empty group variables that we will fill\n",
    "            df['Group2'] = 0\n",
    "            df['Group1'] = 0\n",
    "            df['Group3'] = 0\n",
    "            df['Group0'] = 0\n",
    "\n",
    "            #This is an ordinal variable. There are 4 values, 0, 1, 2, and 3. \n",
    "            #When we dummy code this, there will be 4 variables to indicate group membership\n",
    "            #These are the group totals\n",
    "            #820,71,59,151\n",
    "            gt2 = int(p1[pgroup]*N)\n",
    "            gt1 = int(p2[pgroup]*N)\n",
    "            gt3 = int(p3[pgroup]*N)\n",
    "            gt0 = int(p4[pgroup]*N)\n",
    "\n",
    "            #Puts 1's in the dataframe for the appropriate number of groups\n",
    "            df.loc[df.index < gt2,'Group2'] = 1\n",
    "            df.loc[(df.index >= gt2)&(df.index < gt1+gt2),'Group1'] = 1\n",
    "            df.loc[(df.index >= gt1+gt2)&(df.index < gt1+gt2+gt0),'Group0'] = 1\n",
    "            df.loc[(df.index >= gt1+gt2+gt0)&(df.index < gt1+gt2+gt0+gt3),'Group3'] = 1\n",
    "\n",
    "            #randomly shuffles the dataframe so not all of group 2 is at the beginning\n",
    "            df = df.iloc[np.random.permutation(len(df))]\n",
    "            df = df.reset_index(drop=True)\n",
    "\n",
    "            #gets rid of variables I don't need\n",
    "            df = df[['Group2','Group3','Group1','Group0','v1','v2','v3','v4','v5']]\n",
    "\n",
    "            #within .01, an order of magnitude less\n",
    "            #these are the ideal correlations between all 9 of the variables\n",
    "            Cor2 = np.array([1, cor12, cor13, cor14, .551, -.152, .103, -.080, -.024]) #APClass passed test\n",
    "            Cor3 = np.array([cor12, 1, cor23, cor24, .006, -.023, .021, -.019, -.014]) #APClass no test\n",
    "            Cor1 = np.array([cor13, cor23, 1, cor34, .011, -.043, .057, -.056, -.028]) #class no pass test\n",
    "            Cor0 = np.array([cor14, cor24, cor34, 1, -.475, .156, -.125, .105, .042])  #no AP class\n",
    "\n",
    "            #a penalization factor to minimize the difference between the actual correlations and the ideal correlations\n",
    "            power = 5\n",
    "\n",
    "            dfa = np.array(df).T\n",
    "\n",
    "            # map group number to column index\n",
    "            group_index = {2: 0,\n",
    "                           3: 1,\n",
    "                           1: 2,\n",
    "                           0: 3}\n",
    "\n",
    "            def set_group_membership(dfa, y, g0, g1, g2, g3):\n",
    "                dfa[group_index[0], y] = g0\n",
    "                dfa[group_index[1], y] = g1\n",
    "                dfa[group_index[2], y] = g2\n",
    "                dfa[group_index[3], y] = g3\n",
    "\n",
    "                return dfa\n",
    "\n",
    "            def calculate_sum_error(dfa):\n",
    "                # calculate the corellation coefficient matrix for the whole 2D array\n",
    "                tmp_corr = np.corrcoef(dfa)\n",
    "\n",
    "                sm = 0\n",
    "\n",
    "                # Calculate the difference between the actual correlations and the ideal correlations\n",
    "                # Add 1 and take it to some power to minimize large correlations\n",
    "                sm += np.sum(np.power(1 + np.abs(tmp_corr[group_index[0], :] - Cor0), power))\n",
    "                sm += np.sum(np.power(1 + np.abs(tmp_corr[group_index[1], :] - Cor1), power))\n",
    "                sm += np.sum(np.power(1 + np.abs(tmp_corr[group_index[2], :] - Cor2), power))\n",
    "                sm += np.sum(np.power(1 + np.abs(tmp_corr[group_index[3], :] - Cor3), power))\n",
    "                \n",
    "                return sm\n",
    "\n",
    "            def choose_best_group(dfa, y, sum0, sum1, sum2, sum3):\n",
    "                if (sum0 < sum1) and (sum0 < sum2) and (sum0 < sum3):   # sum0 is smallest\n",
    "                    return set_group_membership(dfa, y, 1, 0, 0, 0)\n",
    "                elif (sum1 < sum0) and (sum1 < sum2) and (sum1 < sum3): # sum1 is smallest\n",
    "                    return set_group_membership(dfa, y, 0, 1, 0, 0)\n",
    "                elif (sum2 < sum0) and (sum2 < sum1) and (sum2 < sum3): # sum2 is smallest\n",
    "                    return set_group_membership(dfa, y, 0, 0, 1, 0)\n",
    "                elif (sum3 < sum0) and (sum3 < sum1) and (sum3 < sum2): # sum3 is smallest\n",
    "                    return set_group_membership(dfa, y, 0, 0, 0, 1)\n",
    "                else:\n",
    "                    # shouldn't ever get here! If we do, it means that there was more\n",
    "                    # than one minimum with the same same sum of error.\n",
    "                    raise Exception(\"More than one minimum sum! \" + sum2 + \", \" + sum1 + \", \" + sum0 + \", \" + sum3)\n",
    "\n",
    "                return dfa\n",
    "\n",
    "            for y in range(dfa.shape[1]):\n",
    "                #put the person in Group 0\n",
    "                dfa = set_group_membership(dfa, y, 1, 0, 0, 0)\n",
    "                sum0 = calculate_sum_error(dfa)\n",
    "\n",
    "                #put the person in Group 1\n",
    "                dfa = set_group_membership(dfa, y, 0, 1, 0, 0)\n",
    "                sum1 = calculate_sum_error(dfa)\n",
    "\n",
    "                #put the person in Group 2\n",
    "                dfa = set_group_membership(dfa, y, 0, 0, 1, 0)\n",
    "                sum2 = calculate_sum_error(dfa)\n",
    "\n",
    "                #put the person in Group 3\n",
    "                dfa = set_group_membership(dfa, y, 0, 0, 0, 1)\n",
    "                sum3 = calculate_sum_error(dfa)\n",
    "\n",
    "                dfa = choose_best_group(dfa, y, sum0, sum1, sum2, sum3)\n",
    "\n",
    "            #we oversampled to get correct group membership\n",
    "            #this brings sample size back down to what we want\n",
    "            N = int(N/1.25)\n",
    "            count_index = {\n",
    "                0:int(round(p1[pgroup]*N)),#2998\n",
    "                1:int(round(p2[pgroup]*N)),#1166\n",
    "                2:int(round(p3[pgroup]*N)),#1407\n",
    "                3:int(round(p4[pgroup]*N))#16183\n",
    "            }\n",
    "\n",
    "            df = pd.DataFrame(dfa.T)\n",
    "            \n",
    "            #randomly pull out samples (the right number) for each group\n",
    "            for group in range(4):\n",
    "                tmp = df[df[group] == 1].copy()\n",
    "                tmp['random'] = 0\n",
    "                tmp['random'] = tmp['random'].apply(lambda x: np.random.normal())\n",
    "                tmp = tmp.sort_values('random')\n",
    "                tmp = tmp.reset_index(drop=True)\n",
    "                tmp = tmp[0:count_index[group]]\n",
    "                if group == 0:\n",
    "                    tmp2 = tmp.copy()\n",
    "                    continue\n",
    "                pieces = [tmp2,tmp]\n",
    "                tmp2 = pd.concat(pieces)\n",
    "\n",
    "            #calculate the correlation matrix difference between desired and simulated  \n",
    "            df3 = pd.DataFrame(0,index=range(9),columns=['G2','G3','G1','G0'])\n",
    "            for x in range(9):\n",
    "                df3.loc[x,'G2'] = np.corrcoef(tmp2[0],tmp2[tmp2.columns[x]])[0][1] - Cor2[x]\n",
    "                df3.loc[x,'G1'] = np.corrcoef(tmp2[2],tmp2[tmp2.columns[x]])[0][1] - Cor1[x]\n",
    "                df3.loc[x,'G0'] = np.corrcoef(tmp2[3],tmp2[tmp2.columns[x]])[0][1] - Cor0[x]\n",
    "                df3.loc[x,'G3'] = np.corrcoef(tmp2[1],tmp2[tmp2.columns[x]])[0][1] - Cor3[x]\n",
    "            midpoint2 = time.time()\n",
    "            \n",
    "            #modify original data based on covariate changes\n",
    "            tmp = tmp2.copy()\n",
    "            for cov_change in cov_changes:\n",
    "                tmp2 = tmp.copy()\n",
    "                \n",
    "                if cov_change[0] == 1:\n",
    "                    tmp2[8] = tmp2[0] + tmp2[8]\n",
    "                if cov_change[1] == -1:\n",
    "                    tmp2[8] = tmp2[0] + tmp2[0] + tmp2[8] + [-1] * len(tmp2[8])\n",
    "                \n",
    "                #2 different analysis scripts\n",
    "                #avg beta = 0 runs a separate logistic regression for each group\n",
    "                #avg beta = 1 averages betas across all group logistic regressions\n",
    "                \n",
    "\n",
    "                for avgbeta in avgbetas:\n",
    "                    if avgbeta == 0:\n",
    "                        for grouping in groups:\n",
    "                            for cov_elim in cov_elims:\n",
    "                                \n",
    "                                dfa2 = tmp2[(tmp2[grouping[0]]==1)|(tmp2[grouping[1]]==1)].copy()\n",
    "\n",
    "                                mydf = dfa2.copy()\n",
    "                                newCorr = pearsonr(mydf[grouping[0]],mydf[4])[0]\n",
    "\n",
    "                                #this is our dependent variable\n",
    "                                y = dfa2[grouping[0]]\n",
    "                                y = np.asarray(y, dtype=\"|S6\")\n",
    "\n",
    "                                dfagroup1 = tmp2[(tmp2[grouping[0]]==1)]\n",
    "                                dfagroup2 = tmp2[(tmp2[grouping[1]]==1)]\n",
    "                                meangroup1 = dfagroup1[4].mean()\n",
    "                                meangroup2 = dfagroup2[4].mean()\n",
    "                                mediangroup1 = np.median(dfagroup1[4])\n",
    "                                mediangroup2 = np.median(dfagroup2[4])\n",
    "                                stdgroup1 = dfagroup1[4].std(ddof=1)\n",
    "                                stdgroup2 = dfagroup2[4].std(ddof=1)\n",
    "                                pooledstd = dfa2[4].std(ddof=1)\n",
    "\n",
    "                                simpleCohenMeasure = (meangroup1 - meangroup2) / pooledstd\n",
    "\n",
    "                                #these are our independent variables\n",
    "                                if cov_elim == 0:\n",
    "                                    X = np.array(dfa2[[5,6,7,8]])\n",
    "                                elif cov_elim == 1:\n",
    "                                    X = np.array(dfa2[[6,7,8]])\n",
    "\n",
    "                                #initiate the model and fit it\n",
    "                                model = LogisticRegression()\n",
    "                                model = model.fit(X, y)\n",
    "                                probs = model.predict_proba(X)\n",
    "                                one_prob = probs[:,1]\n",
    "                                seq = []\n",
    "\n",
    "                                sep = 100.0 / stratify_level\n",
    "                                for xy3 in range(stratify_level):\n",
    "                                    seq.append((xy3+1)*sep)\n",
    "                                seq = seq[:-1]\n",
    "    #                             seq = [10,20,25,30,40,50,60,70,80,90]\n",
    "    #                             stratify_level = 11\n",
    "                                dec1 = np.percentile(one_prob,seq)\n",
    "                                dfa2 = np.array(dfa2.T)\n",
    "                                final_dict_strat = {}\n",
    "\n",
    "                                ###for simple regression\n",
    "                                y2 = np.array(tmp2[(tmp2[grouping[0]]==1)|(tmp2[grouping[1]]==1)][4])\n",
    "                                if cov_elim == 0:\n",
    "                                    X2 = np.array(tmp2[(tmp2[grouping[0]]==1)|(tmp2[grouping[1]]==1)][[grouping[0],5,6,7,8]])\n",
    "                                elif cov_elim == 1:\n",
    "                                    X2 = np.array(tmp2[(tmp2[grouping[0]]==1)|(tmp2[grouping[1]]==1)][[grouping[0],6,7,8]])\n",
    "                                X2 = sm.add_constant(X2)\n",
    "                                model = sm.OLS(y2,X2)\n",
    "                                results = model.fit()\n",
    "\n",
    "                                linear_regression_result = (results.params[1]) / tmp2[(tmp2[grouping[0]]==1)|(tmp2[grouping[1]]==1)][4].std(ddof=1)\n",
    "\n",
    "                                ###for stratification on propensities (weighted average)\n",
    "                                for group_comp in range(len(seq)-1):\n",
    "                                    final_dict_strat['treatment{}'.format(group_comp+1)] = dfa2[4][(dfa2[grouping[0]]==1)&(one_prob<=dec1[group_comp+1])&(one_prob>dec1[group_comp])]\n",
    "                                    final_dict_strat['control{}'.format(group_comp+1)] = dfa2[4][(dfa2[grouping[1]]==1)&(one_prob<=dec1[group_comp+1])&(one_prob>dec1[group_comp])]\n",
    "                                final_dict_strat['treatment{}'.format(0)] = dfa2[4][(dfa2[grouping[0]]==1)&(one_prob<=dec1[0])]\n",
    "                                final_dict_strat['control{}'.format(0)] = dfa2[4][(dfa2[grouping[1]]==1)&(one_prob<=dec1[0])]\n",
    "                                final_dict_strat['treatment{}'.format(stratify_level-1)] = dfa2[4][(dfa2[grouping[0]]==1)&(one_prob>dec1[len(seq)-1])]\n",
    "                                final_dict_strat['control{}'.format(stratify_level-1)] = dfa2[4][(dfa2[grouping[1]]==1)&(one_prob>dec1[len(seq)-1])]\n",
    "\n",
    "                                effect_sizes = []\n",
    "                                for x in range(stratify_level):\n",
    "                                    #mean difference between groups divided by pooled standard deviation\n",
    "                                    effect_size = (final_dict_strat['treatment{}'.format(x)].mean() - final_dict_strat['control{}'.format(x)].mean())/\\\n",
    "                                                    (np.array(list(final_dict_strat['treatment{}'.format(x)]) + list(final_dict_strat['control{}'.format(x)]))).std(ddof=1)\n",
    "                                    if effect_size == effect_size:\n",
    "                                        effect_sizes.append(effect_size)\n",
    "                                    else:\n",
    "                                        pass\n",
    "\n",
    "                                #calculate Cohen's D as the mean of all effect sizes across deciles\n",
    "                                if np.array(effect_sizes).mean() == np.array(effect_sizes).mean():\n",
    "                                    CohenD = np.array(effect_sizes).mean()\n",
    "                                else:\n",
    "                                    CohenD = None\n",
    "\n",
    "                                #####\n",
    "                                final_dict = {}\n",
    "                                ###for weighted least squares regression\n",
    "                                test = tmp2[(tmp2[grouping[0]]==1)|(tmp2[grouping[1]]==1)].copy()\n",
    "                                treatmentw = (1/one_prob[(dfa2[grouping[0]]==1)])/((1/one_prob[(dfa2[grouping[0]]==1)]).sum())\n",
    "                                controlw = (1/(1-one_prob[(dfa2[grouping[1]]==1)]))/((1/(1-one_prob[(dfa2[grouping[1]]==1)])).sum())\n",
    "                                test.loc[test[grouping[0]] == 1,'weight'] = treatmentw\n",
    "                                test.loc[test[grouping[1]] == 1,'weight'] = controlw\n",
    "                                w = np.array(test['weight'])\n",
    "                                mod_wls = sm.WLS(y2, X2, weights = w)\n",
    "                                res_wls = mod_wls.fit()\n",
    "                                weighted_regression_result = (res_wls.params[1]) / tmp2[4].std(ddof=1)\n",
    "\n",
    "                                #simpleCohenMeasure\n",
    "                                #linear_regression_result\n",
    "                                #weighted_regression_result\n",
    "                                differences = []\n",
    "                                for g in range(1,stratify_level-2):\n",
    "                                    for f in [5,6,7,8]:\n",
    "                                        group1value = dfa2[f][(dfa2[grouping[0]]==1)&(one_prob<=dec1[g])&(one_prob>dec1[g-1])].mean()\n",
    "                                        group2value = dfa2[f][(dfa2[grouping[1]]==1)&(one_prob<=dec1[g])&(one_prob>dec1[g-1])].mean()\n",
    "                                        difference = group1value - group2value\n",
    "                                        differences.append(difference)\n",
    "                                #for the first stratum\n",
    "                                for f in [5,6,7,8]:\n",
    "                                    group1value = (dfa2[f][(dfa2[grouping[0]]==1)&(one_prob>dec1[stratify_level-2])]).mean()\n",
    "                                    group2value = (dfa2[f][(dfa2[grouping[1]]==1)&(one_prob>dec1[stratify_level-2])]).mean()\n",
    "                                    difference = group1value - group2value\n",
    "                                    differences.append(difference)\n",
    "                                #for the last stratum\n",
    "                                for f in [5,6,7,8]:\n",
    "                                    group1value = (dfa2[f][(dfa2[grouping[0]]==1)&(one_prob<dec1[0])]).mean()\n",
    "                                    group2value = (dfa2[f][(dfa2[grouping[1]]==1)&(one_prob<dec1[0])]).mean()\n",
    "                                    difference = group1value - group2value\n",
    "                                    differences.append(difference)\n",
    "\n",
    "                                covariate_diff = np.sum(np.abs(differences))\n",
    "                                differences2 = []\n",
    "                                ##############ONE PROB###\n",
    "                                for g in range(1,stratify_level-2):\n",
    "                                    for f in [5,6,7,8]:\n",
    "                                        group1value = one_prob[(dfa2[grouping[0]]==1)&(one_prob<=dec1[g])&(one_prob>dec1[g-1])].mean()\n",
    "                                        group2value = one_prob[(dfa2[grouping[1]]==1)&(one_prob<=dec1[g])&(one_prob>dec1[g-1])].mean()\n",
    "                                        difference = group1value - group2value\n",
    "                                        differences2.append(difference)\n",
    "                                for f in [5,6,7,8]:\n",
    "                                    group1value = (one_prob[(dfa2[grouping[0]]==1)&(one_prob>dec1[stratify_level-2])]).mean()\n",
    "                                    group2value = (one_prob[(dfa2[grouping[1]]==1)&(one_prob>dec1[stratify_level-2])]).mean()\n",
    "                                    difference = group1value - group2value\n",
    "                                    differences2.append(difference)\n",
    "                                for f in [5,6,7,8]:\n",
    "                                    group1value = (one_prob[(dfa2[grouping[0]]==1)&(one_prob<dec1[0])]).mean()\n",
    "                                    group2value = (one_prob[(dfa2[grouping[1]]==1)&(one_prob<dec1[0])]).mean()\n",
    "                                    difference = group1value - group2value\n",
    "                                    differences2.append(difference)\n",
    "\n",
    "                                propensity_diff = np.sum(np.abs(differences))\n",
    "\n",
    "                                ###############\n",
    "                                unbalanced = []\n",
    "                                for g in range(1,stratify_level-2):\n",
    "                                    for f in [5,6,7,8]:\n",
    "                                        group0 = dfa2[f][(dfa2[grouping[0]]==1)&(one_prob<=dec1[g])&(one_prob>dec1[g-1])]\n",
    "                                        group1 = dfa2[f][(dfa2[grouping[1]]==1)&(one_prob<=dec1[g])&(one_prob>dec1[g-1])]\n",
    "                                        if len(group0) < 2 or len(group1) < 2:\n",
    "                                            pass\n",
    "                                        else:\n",
    "                                            sig = ttest(group0,group1)[1]\n",
    "                                            if sig < .05:\n",
    "                                                unbalanced.append({'group#':g,\n",
    "                                                                  'variable#':f,\n",
    "                                                                  'group0size':len(group0),\n",
    "                                                                  'group1size':len(group1),\n",
    "                                                                  'p-value':sig})\n",
    "                                for f in [5,6,7,8]:\n",
    "                                    g = stratify_level-1\n",
    "                                    group0 = (dfa2[f][(dfa2[grouping[0]]==1)&(one_prob>dec1[stratify_level-2])])\n",
    "                                    group1 = (dfa2[f][(dfa2[grouping[1]]==1)&(one_prob>dec1[stratify_level-2])])\n",
    "                                    if len(group0) < 2 or len(group1) < 2:\n",
    "                                        pass\n",
    "                                    else:\n",
    "                                        sig = ttest(group0,group1)[1]\n",
    "                                        if sig < .05:\n",
    "                                            unbalanced.append({'group#':g,\n",
    "                                                                  'variable#':f,\n",
    "                                                                  'group0size':len(group0),\n",
    "                                                                  'group1size':len(group1),\n",
    "                                                                  'p-value':sig})\n",
    "                                    #for the last stratum\n",
    "                                for f in [5,6,7,8]:\n",
    "                                    g = 0\n",
    "                                    group0 = (dfa2[f][(dfa2[grouping[0]]==1)&(one_prob<dec1[0])])\n",
    "                                    group1 = (dfa2[f][(dfa2[grouping[1]]==1)&(one_prob<dec1[0])])\n",
    "                                    if len(group0) < 2 or len(group1) < 2:\n",
    "                                        pass\n",
    "                                    else:\n",
    "                                        sig = ttest(group0,group1)[1]\n",
    "                                        if sig < .05:\n",
    "                                            unbalanced.append({'group#':g,\n",
    "                                                                  'variable#':f,\n",
    "                                                                  'group0size':len(group0),\n",
    "                                                                  'group1size':len(group1),\n",
    "                                                                  'p-value':sig})\n",
    "                                ###############\n",
    "\n",
    "                                ###\n",
    "                                counting1 = []\n",
    "                                counting2 = []\n",
    "                                for x in range(stratify_level):\n",
    "                                    counting1.append(len(final_dict_strat['treatment{}'.format(x)]))\n",
    "                                    counting2.append(len(final_dict_strat['control{}'.format(x)]))\n",
    "\n",
    "\n",
    "                                #Simple Stratification\n",
    "                                #using binary cutoff points for covariates (greater than median is set to 1, less than median is set to 0)\n",
    "                                ###############\n",
    "                                tmp2[15] = tmp2[5].map(lambda x: 1 if x > tmp2[5].median() else 0)\n",
    "                                tmp2[16] = tmp2[6].map(lambda x: 1 if x > tmp2[6].median() else 0)\n",
    "                                tmp2[17] = tmp2[7].map(lambda x: 1 if x > tmp2[7].median() else 0)\n",
    "                                tmp2[18] = tmp2[8].map(lambda x: 1 if x > tmp2[8].median() else 0)\n",
    "\n",
    "                                tmp2['group'] = tmp2[15].astype(str) + tmp2[16].astype(str) + tmp2[17].astype(str) + tmp2[18].astype(str)\n",
    "\n",
    "                                groups2 = ['0000','0001','0010','0011','0100','0101','0110','0111','1000','1001','1010','1011','1100','1101','1110','1111']\n",
    "\n",
    "                                finalresult = 0\n",
    "                                for group in groups2:\n",
    "                                    meantreatment = tmp2[(tmp2.group == group)&(tmp2[grouping[0]] == 1)][4].mean()\n",
    "                                    meancontrol = tmp2[(tmp2.group == group)&(tmp2[grouping[1]] == 1)][4].mean()\n",
    "                                    temp = tmp2[(tmp2.group == group)&((tmp2[grouping[1]] == 1)|(tmp2[grouping[0]] == 1))].copy()\n",
    "                                    groupstd = temp[4].std(ddof=1)\n",
    "                                    result = (meantreatment - meancontrol) / groupstd\n",
    "\n",
    "                                    groupmembership = len(temp[4])\n",
    "                                    total = float(len(tmp2[((tmp2[grouping[1]] == 1)|(tmp2[grouping[0]] == 1))][4]))\n",
    "                                    weight = groupmembership / total\n",
    "\n",
    "                                    if result == result and weight == weight:\n",
    "                                        finalresult += result * weight\n",
    "\n",
    "                                unbalanced2 = []\n",
    "                                for g in groups2:\n",
    "                                    for f in [5,6,7,8]:\n",
    "                                        group0 = tmp2[(tmp2[grouping[0]]==1)&(tmp2.group == g)][f]\n",
    "                                        group1 = tmp2[(tmp2[grouping[1]]==1)&(tmp2.group == g)][f]\n",
    "                                        if len(group0) < 2 or len(group1) < 2:\n",
    "                                            pass\n",
    "                                        else:\n",
    "                                            sig = ttest(group0,group1)[1]\n",
    "                                            if sig < .05:\n",
    "                                                unbalanced2.append({'group#':g,\n",
    "                                                                  'variable#':f,\n",
    "                                                                  'group0size':len(group0),\n",
    "                                                                  'group1size':len(group1),\n",
    "                                                                  'p-value':sig})\n",
    "                                ###############\n",
    "\n",
    "                                if 'variable#' in pd.DataFrame(unbalanced2).columns:\n",
    "                                    unbalancedSSvar = pd.DataFrame(unbalanced2)['variable#'].values\n",
    "                                else:\n",
    "                                    unbalancedSSvar = None\n",
    "                                if 'group#' in pd.DataFrame(unbalanced2).columns:\n",
    "                                    unbalancedSSgroup = pd.DataFrame(unbalanced2)['group#'].values\n",
    "                                else:\n",
    "                                    unbalancedSSgroup = None\n",
    "                                if 'variable#' in pd.DataFrame(unbalanced).columns:\n",
    "                                    unbalancedCSvar = pd.DataFrame(unbalanced)['variable#'].values\n",
    "                                else:\n",
    "                                    unbalancedCSvar = None\n",
    "                                if 'group#' in pd.DataFrame(unbalanced).columns:\n",
    "                                    unbalancedCSgroup = pd.DataFrame(unbalanced)['group#'].values\n",
    "                                else:\n",
    "                                    unbalancedCSgroup = None\n",
    "\n",
    "\n",
    "\n",
    "                                #final output\n",
    "                                final_effect_sizes.append({'Treatment':grouping[0],\n",
    "                                                           'Control':grouping[1],\n",
    "                                                           'Proportion':pgroup,\n",
    "                                                           'N':N,\n",
    "                                                           'Sim#':z,\n",
    "                                                           'CovMatrix':tmp2.corr(),\n",
    "                                                           'CorrDiff':df3.abs().sum().sum(),\n",
    "                                                           'AvgBeta':avgbeta,\n",
    "                                                           'CovChange':cov_change,\n",
    "                                                           'simpleCohenMeasure':simpleCohenMeasure,\n",
    "                                                           'linear_regression_result':linear_regression_result,\n",
    "                                                           'weighted_regression_result':weighted_regression_result,\n",
    "                                                           'stratifiedCohenMeasure':CohenD,\n",
    "                                                           'meangroup1':meangroup1,\n",
    "                                                           'meangroup2':meangroup2,\n",
    "                                                           'stdgroup1':stdgroup1,\n",
    "                                                           'stdgroup2':stdgroup2,\n",
    "                                                           'mediangroup1':mediangroup1,\n",
    "                                                           'mediangroup2':mediangroup2,\n",
    "                                                           'covariate_diff':covariate_diff,\n",
    "                                                           'propensity_diff':propensity_diff,\n",
    "                                                           'counting1':counting1,\n",
    "                                                           'counting2':counting2,\n",
    "                                                           'newCorr':newCorr,\n",
    "                                                           'simplestratification':finalresult,\n",
    "                                                           'unbalancedSSvar#':unbalancedSSvar,\n",
    "                                                           'unbalancedSSgroup#':unbalancedSSgroup,\n",
    "                                                           'unbalancedCSvar#':unbalancedCSvar,\n",
    "                                                           'unbalancedCSgroup#':unbalancedCSgroup,\n",
    "                                                           'covariate_elimination':cov_elim\n",
    "                                                            })\n",
    "                    else:\n",
    "                        for cov_elim in cov_elims:\n",
    "                            coefficient1 = []\n",
    "                            coefficient2 = []\n",
    "                            coefficient3 = []\n",
    "                            coefficient4 = []\n",
    "                            intercept = []\n",
    "                            for grouping in groups:\n",
    "\n",
    "                                dfa2 = tmp2[(tmp2[grouping[0]]==1)|(tmp2[grouping[1]]==1)].copy()\n",
    "\n",
    "                                #this is our dependent variable\n",
    "                                y = dfa2[grouping[0]]\n",
    "                                y = np.asarray(y, dtype=\"|S6\")\n",
    "\n",
    "                                #these are our independent variables\n",
    "                                if cov_elim == 0:\n",
    "                                    X = np.array(dfa2[[5,6,7,8]])\n",
    "                                elif cov_elim == 1:\n",
    "                                    X = np.array(dfa2[[6,7,8]])\n",
    "                                #initiate the model and fit it\n",
    "                                model = LogisticRegression()\n",
    "                                model = model.fit(X, y)\n",
    "                                if cov_elim == 0:\n",
    "                                    coefficient1.append(model.coef_[0][0])\n",
    "                                    coefficient2.append(model.coef_[0][1])\n",
    "                                    coefficient3.append(model.coef_[0][2])\n",
    "                                    coefficient4.append(model.coef_[0][3])\n",
    "                                    intercept.append(model.intercept_)\n",
    "                                elif cov_elim == 1:\n",
    "                                    coefficient2.append(model.coef_[0][0])\n",
    "                                    coefficient3.append(model.coef_[0][1])\n",
    "                                    coefficient4.append(model.coef_[0][2])\n",
    "                                    intercept.append(model.intercept_)\n",
    "                            if cov_elim == 0:\n",
    "                                coefficient_1 = np.array(coefficient1).mean()\n",
    "                                coefficient_2 = np.array(coefficient2).mean()\n",
    "                                coefficient_3 = np.array(coefficient3).mean()\n",
    "                                coefficient_4 = np.array(coefficient4).mean()\n",
    "                                intercept1 = np.array(intercept).mean()\n",
    "                            elif cov_elim == 1:\n",
    "                                coefficient_2 = np.array(coefficient2).mean()\n",
    "                                coefficient_3 = np.array(coefficient3).mean()\n",
    "                                coefficient_4 = np.array(coefficient4).mean()\n",
    "                                intercept1 = np.array(intercept).mean()\n",
    "\n",
    "                            for grouping in groups:\n",
    "\n",
    "                                dfa2 = tmp2[(tmp2[grouping[0]]==1)|(tmp2[grouping[1]]==1)].copy()\n",
    "\n",
    "                                mydf = dfa2.copy()\n",
    "                                newCorr = pearsonr(mydf[grouping[0]],mydf[4])[0]\n",
    "\n",
    "                                #this is our dependent variable\n",
    "                                y = dfa2[grouping[0]]\n",
    "                                y = np.asarray(y, dtype=\"|S6\")\n",
    "\n",
    "                                dfagroup1 = tmp2[(tmp2[grouping[0]]==1)]\n",
    "                                dfagroup2 = tmp2[(tmp2[grouping[1]]==1)]\n",
    "                                meangroup1 = dfagroup1[4].mean()\n",
    "                                meangroup2 = dfagroup2[4].mean()\n",
    "                                mediangroup1 = np.median(dfagroup1[4])\n",
    "                                mediangroup2 = np.median(dfagroup2[4])\n",
    "                                stdgroup1 = dfagroup1[4].std(ddof=1)\n",
    "                                stdgroup2 = dfagroup2[4].std(ddof=1)\n",
    "                                pooledstd = dfa2[4].std(ddof=1)\n",
    "\n",
    "                                simpleCohenMeasure = (meangroup1 - meangroup2) / pooledstd\n",
    "\n",
    "                                #independent variables\n",
    "                                if cov_elim == 0:\n",
    "                                    X = np.array(dfa2[[5,6,7,8,]])\n",
    "                                elif cov_elim == 1:\n",
    "                                    X = np.array(dfa2[[6,7,8]])\n",
    "\n",
    "                                #create the model and probabilities\n",
    "                                if cov_elim == 0:\n",
    "                                    logs = intercept1 + X[:,0]*coefficient_1 + X[:,1]*coefficient_2 + \\\n",
    "                                                    X[:,2]*coefficient_3 + X[:,3]*coefficient_4\n",
    "                                elif cov_elim == 1:\n",
    "                                    logs = intercept1 + X[:,0]*coefficient_2 + \\\n",
    "                                                    X[:,1]*coefficient_3 + X[:,2]*coefficient_4\n",
    "                                def logToProb(value):\n",
    "                                    return math.exp(value)/(1+math.exp(value))\n",
    "                                logToProb = np.vectorize(logToProb)\n",
    "\n",
    "                                one_prob = logToProb(logs)\n",
    "\n",
    "                                ######\n",
    "\n",
    "                                dfagroup1 = tmp2[(tmp2[grouping[0]]==1)]\n",
    "                                dfagroup2 = tmp2[(tmp2[grouping[1]]==1)]\n",
    "                                meangroup1 = dfagroup1[4].mean()\n",
    "                                meangroup2 = dfagroup2[4].mean()\n",
    "                                mediangroup1 = np.median(dfagroup1[4])\n",
    "                                mediangroup2 = np.median(dfagroup2[4])\n",
    "                                stdgroup1 = dfagroup1[4].std(ddof=1)\n",
    "                                stdgroup2 = dfagroup2[4].std(ddof=1)\n",
    "                                pooledstd = dfa2[4].std(ddof=1)\n",
    "\n",
    "                                simpleCohenMeasure = (meangroup1 - meangroup2) / pooledstd\n",
    "\n",
    "                                #these are our independent variables\n",
    "                                if cov_elim == 0:\n",
    "                                    X = np.array(dfa2[[5,6,7,8]])\n",
    "                                elif cov_elim == 1:\n",
    "                                    X = np.array(dfa2[[6,7,8]])\n",
    "\n",
    "                                seq = []\n",
    "\n",
    "                                sep = 100.0 / stratify_level\n",
    "                                for xy3 in range(stratify_level):\n",
    "                                    seq.append((xy3+1)*sep)\n",
    "                                seq = seq[:-1]\n",
    "                                dec1 = np.percentile(one_prob,seq)\n",
    "                                dfa2 = np.array(dfa2.T)\n",
    "                                final_dict_strat = {}\n",
    "\n",
    "                                ###for simple regression\n",
    "                                y2 = np.array(tmp2[(tmp2[grouping[0]]==1)|(tmp2[grouping[1]]==1)][4])\n",
    "                                if cov_elim == 0:\n",
    "                                    X2 = np.array(tmp2[(tmp2[grouping[0]]==1)|(tmp2[grouping[1]]==1)][[grouping[0],5,6,7,8]])\n",
    "                                elif cov_elim == 1:\n",
    "                                    X2 = np.array(tmp2[(tmp2[grouping[0]]==1)|(tmp2[grouping[1]]==1)][[grouping[0],6,7,8]])\n",
    "                                X2 = sm.add_constant(X2)\n",
    "                                model = sm.OLS(y2,X2)\n",
    "                                results = model.fit()\n",
    "\n",
    "                                linear_regression_result = (results.params[1]) / tmp2[(tmp2[grouping[0]]==1)|(tmp2[grouping[1]]==1)][4].std(ddof=1)\n",
    "\n",
    "                                ###for stratification on propensities (weighted average)\n",
    "                                for group_comp in range(len(seq)-1):\n",
    "                                    final_dict_strat['treatment{}'.format(group_comp+1)] = dfa2[4][(dfa2[grouping[0]]==1)&(one_prob<=dec1[group_comp+1])&(one_prob>dec1[group_comp])]\n",
    "                                    final_dict_strat['control{}'.format(group_comp+1)] = dfa2[4][(dfa2[grouping[1]]==1)&(one_prob<=dec1[group_comp+1])&(one_prob>dec1[group_comp])]\n",
    "                                final_dict_strat['treatment{}'.format(0)] = dfa2[4][(dfa2[grouping[0]]==1)&(one_prob<=dec1[0])]\n",
    "                                final_dict_strat['control{}'.format(0)] = dfa2[4][(dfa2[grouping[1]]==1)&(one_prob<=dec1[0])]\n",
    "                                final_dict_strat['treatment{}'.format(stratify_level-1)] = dfa2[4][(dfa2[grouping[0]]==1)&(one_prob>dec1[len(seq)-1])]\n",
    "                                final_dict_strat['control{}'.format(stratify_level-1)] = dfa2[4][(dfa2[grouping[1]]==1)&(one_prob>dec1[len(seq)-1])]\n",
    "\n",
    "                                effect_sizes = []\n",
    "                                for x in range(stratify_level):\n",
    "                                    #mean difference between groups divided by pooled standard deviation\n",
    "                                    effect_size = (final_dict_strat['treatment{}'.format(x)].mean() - final_dict_strat['control{}'.format(x)].mean())/\\\n",
    "                                                    (np.array(list(final_dict_strat['treatment{}'.format(x)]) + list(final_dict_strat['control{}'.format(x)]))).std(ddof=1)\n",
    "                                    if effect_size == effect_size:\n",
    "                                        effect_sizes.append(effect_size)\n",
    "                                    else:\n",
    "                                        pass\n",
    "\n",
    "                                #calculate Cohen's D as the mean of all effect sizes across deciles\n",
    "                                if np.array(effect_sizes).mean() == np.array(effect_sizes).mean():\n",
    "                                    CohenD = np.array(effect_sizes).mean()\n",
    "                                else:\n",
    "                                    CohenD = None\n",
    "\n",
    "                                #####\n",
    "                                final_dict = {}\n",
    "                                ###for weighted least squares regression\n",
    "                                test = tmp2[(tmp2[grouping[0]]==1)|(tmp2[grouping[1]]==1)].copy()\n",
    "                                treatmentw = (1/one_prob[(dfa2[grouping[0]]==1)])/((1/one_prob[(dfa2[grouping[0]]==1)]).sum())\n",
    "                                controlw = (1/(1-one_prob[(dfa2[grouping[1]]==1)]))/((1/(1-one_prob[(dfa2[grouping[1]]==1)])).sum())\n",
    "                                test.loc[test[grouping[0]] == 1,'weight'] = treatmentw\n",
    "                                test.loc[test[grouping[1]] == 1,'weight'] = controlw\n",
    "                                w = np.array(test['weight'])\n",
    "                                mod_wls = sm.WLS(y2, X2, weights = w)\n",
    "                                res_wls = mod_wls.fit()\n",
    "                                weighted_regression_result = (results.params[1]) / tmp2[4].std(ddof=1)\n",
    "\n",
    "                                #simpleCohenMeasure\n",
    "                                #linear_regression_result\n",
    "                                #weighted_regression_result\n",
    "                                differences = []\n",
    "                                for g in range(1,stratify_level-2):\n",
    "                                    for f in [5,6,7,8]:\n",
    "                                        group1value = dfa2[f][(dfa2[grouping[0]]==1)&(one_prob<=dec1[g])&(one_prob>dec1[g-1])].mean()\n",
    "                                        group2value = dfa2[f][(dfa2[grouping[1]]==1)&(one_prob<=dec1[g])&(one_prob>dec1[g-1])].mean()\n",
    "                                        difference = group1value - group2value\n",
    "                                        differences.append(difference)\n",
    "                                #for the first stratum\n",
    "                                for f in [5,6,7,8]:\n",
    "                                    group1value = (dfa2[f][(dfa2[grouping[0]]==1)&(one_prob>dec1[stratify_level-2])]).mean()\n",
    "                                    group2value = (dfa2[f][(dfa2[grouping[1]]==1)&(one_prob>dec1[stratify_level-2])]).mean()\n",
    "                                    difference = group1value - group2value\n",
    "                                    differences.append(difference)\n",
    "                                #for the last stratum\n",
    "                                for f in [5,6,7,8]:\n",
    "                                    group1value = (dfa2[f][(dfa2[grouping[0]]==1)&(one_prob<dec1[0])]).mean()\n",
    "                                    group2value = (dfa2[f][(dfa2[grouping[1]]==1)&(one_prob<dec1[0])]).mean()\n",
    "                                    difference = group1value - group2value\n",
    "                                    differences.append(difference)\n",
    "\n",
    "                                covariate_diff = np.sum(np.abs(differences))\n",
    "                                differences2 = []\n",
    "                                ##############ONE PROB###\n",
    "                                for g in range(1,stratify_level-2):\n",
    "                                    for f in [5,6,7,8]:\n",
    "                                        group1value = one_prob[(dfa2[grouping[0]]==1)&(one_prob<=dec1[g])&(one_prob>dec1[g-1])].mean()\n",
    "                                        group2value = one_prob[(dfa2[grouping[1]]==1)&(one_prob<=dec1[g])&(one_prob>dec1[g-1])].mean()\n",
    "                                        difference = group1value - group2value\n",
    "                                        differences2.append(difference)\n",
    "                                for f in [5,6,7,8]:\n",
    "                                    group1value = (one_prob[(dfa2[grouping[0]]==1)&(one_prob>dec1[stratify_level-2])]).mean()\n",
    "                                    group2value = (one_prob[(dfa2[grouping[1]]==1)&(one_prob>dec1[stratify_level-2])]).mean()\n",
    "                                    difference = group1value - group2value\n",
    "                                    differences2.append(difference)\n",
    "                                for f in [5,6,7,8]:\n",
    "                                    group1value = (one_prob[(dfa2[grouping[0]]==1)&(one_prob<dec1[0])]).mean()\n",
    "                                    group2value = (one_prob[(dfa2[grouping[1]]==1)&(one_prob<dec1[0])]).mean()\n",
    "                                    difference = group1value - group2value\n",
    "                                    differences2.append(difference)\n",
    "\n",
    "                                propensity_diff = np.sum(np.abs(differences))\n",
    "\n",
    "                                ###############\n",
    "                                unbalanced = []\n",
    "                                for g in range(1,stratify_level-2):\n",
    "                                    for f in [5,6,7,8]:\n",
    "                                        group0 = dfa2[f][(dfa2[grouping[0]]==1)&(one_prob<=dec1[g])&(one_prob>dec1[g-1])]\n",
    "                                        group1 = dfa2[f][(dfa2[grouping[1]]==1)&(one_prob<=dec1[g])&(one_prob>dec1[g-1])]\n",
    "                                        if len(group0) < 2 or len(group1) < 2:\n",
    "                                            pass\n",
    "                                        else:\n",
    "                                            sig = ttest(group0,group1)[1]\n",
    "                                            if sig < .05:\n",
    "                                                unbalanced.append({'group#':g,\n",
    "                                                                  'variable#':f,\n",
    "                                                                  'group0size':len(group0),\n",
    "                                                                  'group1size':len(group1),\n",
    "                                                                  'p-value':sig})\n",
    "                                for f in [5,6,7,8]:\n",
    "                                    g = stratify_level-1\n",
    "                                    group0 = (dfa2[f][(dfa2[grouping[0]]==1)&(one_prob>dec1[stratify_level-2])])\n",
    "                                    group1 = (dfa2[f][(dfa2[grouping[1]]==1)&(one_prob>dec1[stratify_level-2])])\n",
    "                                    if len(group0) < 2 or len(group1) < 2:\n",
    "                                        pass\n",
    "                                    else:\n",
    "                                        sig = ttest(group0,group1)[1]\n",
    "                                        if sig < .05:\n",
    "                                            unbalanced.append({'group#':g,\n",
    "                                                                  'variable#':f,\n",
    "                                                                  'group0size':len(group0),\n",
    "                                                                  'group1size':len(group1),\n",
    "                                                                  'p-value':sig})\n",
    "                                    #for the last stratum\n",
    "                                for f in [5,6,7,8]:\n",
    "                                    g = 0\n",
    "                                    group0 = (dfa2[f][(dfa2[grouping[0]]==1)&(one_prob<dec1[0])])\n",
    "                                    group1 = (dfa2[f][(dfa2[grouping[1]]==1)&(one_prob<dec1[0])])\n",
    "                                    if len(group0) < 2 or len(group1) < 2:\n",
    "                                        pass\n",
    "                                    else:\n",
    "                                        sig = ttest(group0,group1)[1]\n",
    "                                        if sig < .05:\n",
    "                                            unbalanced.append({'group#':g,\n",
    "                                                                  'variable#':f,\n",
    "                                                                  'group0size':len(group0),\n",
    "                                                                  'group1size':len(group1),\n",
    "                                                                  'p-value':sig})\n",
    "                                ###############\n",
    "\n",
    "                                ###\n",
    "                                counting1 = []\n",
    "                                counting2 = []\n",
    "                                for x in range(stratify_level):\n",
    "                                    counting1.append(len(final_dict_strat['treatment{}'.format(x)]))\n",
    "                                    counting2.append(len(final_dict_strat['control{}'.format(x)]))\n",
    "\n",
    "\n",
    "                                #Simple Stratification\n",
    "                                #using binary cutoff points for covariates (greater than median is set to 1, less than median is set to 0)\n",
    "                                ###############\n",
    "                                tmp2[5].median()\n",
    "                                tmp2[15] = tmp2[5].map(lambda x: 1 if x > tmp2[5].median() else 0)\n",
    "                                tmp2[16] = tmp2[6].map(lambda x: 1 if x > tmp2[6].median() else 0)\n",
    "                                tmp2[17] = tmp2[7].map(lambda x: 1 if x > tmp2[7].median() else 0)\n",
    "                                tmp2[18] = tmp2[8].map(lambda x: 1 if x > tmp2[8].median() else 0)\n",
    "\n",
    "                                tmp2['group'] = tmp2[15].astype(str) + tmp2[16].astype(str) + tmp2[17].astype(str) + tmp2[18].astype(str)\n",
    "\n",
    "                                groups2 = ['0000','0001','0010','0011','0100','0101','0110','0111','1000','1001','1010','1011','1100','1101','1110','1111']\n",
    "\n",
    "                                finalresult = 0\n",
    "                                for group in groups2:\n",
    "                                    meantreatment = tmp2[(tmp2.group == group)&(tmp2[grouping[0]] == 1)][4].mean()\n",
    "                                    meancontrol = tmp2[(tmp2.group == group)&(tmp2[grouping[1]] == 1)][4].mean()\n",
    "                                    temp = tmp2[(tmp2.group == group)&((tmp2[grouping[1]] == 1)|(tmp2[grouping[0]] == 1))].copy()\n",
    "                                    groupstd = temp[4].std(ddof=1)\n",
    "                                    result = (meantreatment - meancontrol) / groupstd\n",
    "\n",
    "                                    groupmembership = len(temp[4])\n",
    "                                    total = float(len(tmp2[((tmp2[grouping[1]] == 1)|(tmp2[grouping[0]] == 1))][4]))\n",
    "                                    weight = groupmembership / total\n",
    "\n",
    "                                    if result == result and weight == weight:\n",
    "                                        finalresult += result * weight\n",
    "\n",
    "                                unbalanced2 = []\n",
    "                                for g in groups2:\n",
    "                                    for f in [5,6,7,8]:\n",
    "                                        group0 = tmp2[(tmp2[grouping[0]]==1)&(tmp2.group == g)][f]\n",
    "                                        group1 = tmp2[(tmp2[grouping[1]]==1)&(tmp2.group == g)][f]\n",
    "                                        sig = ttest(group0,group1)[1]\n",
    "                                        if sig < .05:\n",
    "                                            unbalanced2.append({'group#':g,\n",
    "                                                              'variable#':f,\n",
    "                                                              'group0size':len(group0),\n",
    "                                                              'group1size':len(group1),\n",
    "                                                              'p-value':sig})\n",
    "                                ###############\n",
    "                                if 'variable#' in pd.DataFrame(unbalanced2).columns:\n",
    "                                    unbalancedSSvar = pd.DataFrame(unbalanced2)['variable#'].values\n",
    "                                else:\n",
    "                                    unbalancedSSvar = None\n",
    "                                if 'group#' in pd.DataFrame(unbalanced2).columns:\n",
    "                                    unbalancedSSgroup = pd.DataFrame(unbalanced2)['group#'].values\n",
    "                                else:\n",
    "                                    unbalancedSSgroup = None\n",
    "                                if 'variable#' in pd.DataFrame(unbalanced).columns:\n",
    "                                    unbalancedCSvar = pd.DataFrame(unbalanced)['variable#'].values\n",
    "                                else:\n",
    "                                    unbalancedCSvar = None\n",
    "                                if 'group#' in pd.DataFrame(unbalanced).columns:\n",
    "                                    unbalancedCSgroup = pd.DataFrame(unbalanced)['group#'].values\n",
    "                                else:\n",
    "                                    unbalancedCSgroup = None\n",
    "\n",
    "                                #final output\n",
    "                                final_effect_sizes.append({'Treatment':grouping[0],\n",
    "                                                           'Control':grouping[1],\n",
    "                                                           'Proportion':pgroup,\n",
    "                                                           'N':N,\n",
    "                                                           'Sim#':z,\n",
    "                                                           'CovMatrix':tmp2.corr(),\n",
    "                                                           'CorrDiff':df3.abs().sum().sum(),\n",
    "                                                           'AvgBeta':avgbeta,\n",
    "                                                           'CovChange':cov_change,\n",
    "                                                           'simpleCohenMeasure':simpleCohenMeasure,\n",
    "                                                           'linear_regression_result':linear_regression_result,\n",
    "                                                           'weighted_regression_result':weighted_regression_result,\n",
    "                                                           'stratifiedCohenMeasure':CohenD,\n",
    "                                                           'meangroup1':meangroup1,\n",
    "                                                           'meangroup2':meangroup2,\n",
    "                                                           'stdgroup1':stdgroup1,\n",
    "                                                           'stdgroup2':stdgroup2,\n",
    "                                                           'mediangroup1':mediangroup1,\n",
    "                                                           'mediangroup2':mediangroup2,\n",
    "                                                           'covariate_diff':covariate_diff,\n",
    "                                                           'propensity_diff':propensity_diff,\n",
    "                                                           'counting1':counting1,\n",
    "                                                           'counting2':counting2,\n",
    "                                                           'newCorr':newCorr,\n",
    "                                                           'simplestratification':finalresult,\n",
    "                                                           'unbalancedSSvar#':unbalancedSSvar,\n",
    "                                                           'unbalancedSSgroup#':unbalancedSSgroup,\n",
    "                                                           'unbalancedCSvar#':unbalancedCSvar,\n",
    "                                                           'unbalancedCSgroup#':unbalancedCSgroup,\n",
    "                                                           'covariate_elimination':cov_elim\n",
    "                                                          })\n",
    "finaltest = pd.DataFrame(final_effect_sizes)\n",
    "#finaltest.to_csv('{}_{}.csv'.format(z,time.time()),index=False)\n",
    "end = time.time()\n",
    "total_time = end-start\n",
    "# print(\"Time: \" + str(total_time/60) + \" minutes\")\n",
    "# print(\"Correlation Diff: \" + str(corr_diff))\n",
    "# print \"Final Effect Size: \" + str(final_effect_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "comet_cell_id": "aa3acddc92f76"
   },
   "outputs": [],
   "source": [
    "tmp = finaltest[['AvgBeta','Control','Treatment','CovChange','Proportion','simpleCohenMeasure','simplestratification','stratifiedCohenMeasure','weighted_regression_result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "comet_cell_id": "31352fd916c4e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AvgBeta</th>\n",
       "      <th>Control</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>CovChange</th>\n",
       "      <th>Proportion</th>\n",
       "      <th>simpleCohenMeasure</th>\n",
       "      <th>simplestratification</th>\n",
       "      <th>stratifiedCohenMeasure</th>\n",
       "      <th>weighted_regression_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>0</td>\n",
       "      <td>1.336628</td>\n",
       "      <td>1.321314</td>\n",
       "      <td>1.370916</td>\n",
       "      <td>1.320065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>0</td>\n",
       "      <td>1.336628</td>\n",
       "      <td>1.321314</td>\n",
       "      <td>1.347950</td>\n",
       "      <td>1.356843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>0</td>\n",
       "      <td>1.336628</td>\n",
       "      <td>1.321314</td>\n",
       "      <td>1.343842</td>\n",
       "      <td>1.289228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>0</td>\n",
       "      <td>1.336628</td>\n",
       "      <td>1.321314</td>\n",
       "      <td>1.359434</td>\n",
       "      <td>1.350109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>0</td>\n",
       "      <td>1.336628</td>\n",
       "      <td>1.395899</td>\n",
       "      <td>1.477489</td>\n",
       "      <td>1.455792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>0</td>\n",
       "      <td>1.336628</td>\n",
       "      <td>1.395899</td>\n",
       "      <td>1.427997</td>\n",
       "      <td>1.452227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>0</td>\n",
       "      <td>1.336628</td>\n",
       "      <td>1.395899</td>\n",
       "      <td>1.440211</td>\n",
       "      <td>1.285218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>0</td>\n",
       "      <td>1.336628</td>\n",
       "      <td>1.395899</td>\n",
       "      <td>1.423167</td>\n",
       "      <td>1.354170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, -1)</td>\n",
       "      <td>0</td>\n",
       "      <td>1.336628</td>\n",
       "      <td>0.639603</td>\n",
       "      <td>1.505094</td>\n",
       "      <td>1.400228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, -1)</td>\n",
       "      <td>0</td>\n",
       "      <td>1.336628</td>\n",
       "      <td>0.639603</td>\n",
       "      <td>1.558843</td>\n",
       "      <td>1.442988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, -1)</td>\n",
       "      <td>0</td>\n",
       "      <td>1.336628</td>\n",
       "      <td>0.639603</td>\n",
       "      <td>1.533595</td>\n",
       "      <td>1.277198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, -1)</td>\n",
       "      <td>0</td>\n",
       "      <td>1.336628</td>\n",
       "      <td>0.639603</td>\n",
       "      <td>1.515472</td>\n",
       "      <td>1.362293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.411163</td>\n",
       "      <td>1.399825</td>\n",
       "      <td>1.414415</td>\n",
       "      <td>1.557265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.411163</td>\n",
       "      <td>1.399825</td>\n",
       "      <td>1.417067</td>\n",
       "      <td>1.619656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.411163</td>\n",
       "      <td>1.399825</td>\n",
       "      <td>1.415144</td>\n",
       "      <td>1.592494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.411163</td>\n",
       "      <td>1.399825</td>\n",
       "      <td>1.414948</td>\n",
       "      <td>1.632260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.411163</td>\n",
       "      <td>1.466441</td>\n",
       "      <td>1.498874</td>\n",
       "      <td>1.580835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.411163</td>\n",
       "      <td>1.466441</td>\n",
       "      <td>1.508884</td>\n",
       "      <td>1.625116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.411163</td>\n",
       "      <td>1.466441</td>\n",
       "      <td>1.492401</td>\n",
       "      <td>1.562167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.411163</td>\n",
       "      <td>1.466441</td>\n",
       "      <td>1.521657</td>\n",
       "      <td>1.601370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, -1)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.411163</td>\n",
       "      <td>1.042302</td>\n",
       "      <td>1.499018</td>\n",
       "      <td>1.583942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, -1)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.411163</td>\n",
       "      <td>1.042302</td>\n",
       "      <td>1.408639</td>\n",
       "      <td>1.673126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, -1)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.411163</td>\n",
       "      <td>1.042302</td>\n",
       "      <td>1.505946</td>\n",
       "      <td>1.501512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, -1)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.411163</td>\n",
       "      <td>1.042302</td>\n",
       "      <td>1.423491</td>\n",
       "      <td>1.539589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>2</td>\n",
       "      <td>1.482761</td>\n",
       "      <td>1.539365</td>\n",
       "      <td>1.529771</td>\n",
       "      <td>1.527525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>2</td>\n",
       "      <td>1.482761</td>\n",
       "      <td>1.539365</td>\n",
       "      <td>1.489039</td>\n",
       "      <td>1.585735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>2</td>\n",
       "      <td>1.482761</td>\n",
       "      <td>1.539365</td>\n",
       "      <td>1.524554</td>\n",
       "      <td>1.512944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>2</td>\n",
       "      <td>1.482761</td>\n",
       "      <td>1.539365</td>\n",
       "      <td>1.488523</td>\n",
       "      <td>1.590797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>2</td>\n",
       "      <td>1.482761</td>\n",
       "      <td>1.408741</td>\n",
       "      <td>1.463583</td>\n",
       "      <td>1.477929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>2</td>\n",
       "      <td>1.482761</td>\n",
       "      <td>1.408741</td>\n",
       "      <td>1.490117</td>\n",
       "      <td>1.556242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>2</td>\n",
       "      <td>1.482761</td>\n",
       "      <td>1.408741</td>\n",
       "      <td>1.459808</td>\n",
       "      <td>1.538155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>2</td>\n",
       "      <td>1.482761</td>\n",
       "      <td>1.408741</td>\n",
       "      <td>1.482492</td>\n",
       "      <td>1.625100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, -1)</td>\n",
       "      <td>2</td>\n",
       "      <td>1.482761</td>\n",
       "      <td>0.839380</td>\n",
       "      <td>1.545617</td>\n",
       "      <td>1.091733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, -1)</td>\n",
       "      <td>2</td>\n",
       "      <td>1.482761</td>\n",
       "      <td>0.839380</td>\n",
       "      <td>1.608715</td>\n",
       "      <td>1.143697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, -1)</td>\n",
       "      <td>2</td>\n",
       "      <td>1.482761</td>\n",
       "      <td>0.839380</td>\n",
       "      <td>1.577588</td>\n",
       "      <td>1.588576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, -1)</td>\n",
       "      <td>2</td>\n",
       "      <td>1.482761</td>\n",
       "      <td>0.839380</td>\n",
       "      <td>1.540309</td>\n",
       "      <td>1.693706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>3</td>\n",
       "      <td>1.623678</td>\n",
       "      <td>1.698905</td>\n",
       "      <td>1.702194</td>\n",
       "      <td>1.864823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>3</td>\n",
       "      <td>1.623678</td>\n",
       "      <td>1.698905</td>\n",
       "      <td>1.675271</td>\n",
       "      <td>1.936530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>3</td>\n",
       "      <td>1.623678</td>\n",
       "      <td>1.698905</td>\n",
       "      <td>1.694244</td>\n",
       "      <td>1.788767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>3</td>\n",
       "      <td>1.623678</td>\n",
       "      <td>1.698905</td>\n",
       "      <td>1.677443</td>\n",
       "      <td>1.879119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>3</td>\n",
       "      <td>1.623678</td>\n",
       "      <td>1.319703</td>\n",
       "      <td>1.619284</td>\n",
       "      <td>1.749312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>3</td>\n",
       "      <td>1.623678</td>\n",
       "      <td>1.319703</td>\n",
       "      <td>1.530940</td>\n",
       "      <td>1.773162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>3</td>\n",
       "      <td>1.623678</td>\n",
       "      <td>1.319703</td>\n",
       "      <td>1.623710</td>\n",
       "      <td>1.811306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, 0)</td>\n",
       "      <td>3</td>\n",
       "      <td>1.623678</td>\n",
       "      <td>1.319703</td>\n",
       "      <td>1.527642</td>\n",
       "      <td>1.902721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, -1)</td>\n",
       "      <td>3</td>\n",
       "      <td>1.623678</td>\n",
       "      <td>0.967877</td>\n",
       "      <td>1.636683</td>\n",
       "      <td>1.432312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, -1)</td>\n",
       "      <td>3</td>\n",
       "      <td>1.623678</td>\n",
       "      <td>0.967877</td>\n",
       "      <td>1.607365</td>\n",
       "      <td>1.441657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, -1)</td>\n",
       "      <td>3</td>\n",
       "      <td>1.623678</td>\n",
       "      <td>0.967877</td>\n",
       "      <td>1.636124</td>\n",
       "      <td>1.856383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(1, -1)</td>\n",
       "      <td>3</td>\n",
       "      <td>1.623678</td>\n",
       "      <td>0.967877</td>\n",
       "      <td>1.607407</td>\n",
       "      <td>1.949924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AvgBeta  Control  Treatment CovChange  Proportion  simpleCohenMeasure  \\\n",
       "8          0        3          0    (0, 0)           0            1.336628   \n",
       "9          0        3          0    (0, 0)           0            1.336628   \n",
       "16         1        3          0    (0, 0)           0            1.336628   \n",
       "22         1        3          0    (0, 0)           0            1.336628   \n",
       "32         0        3          0    (1, 0)           0            1.336628   \n",
       "33         0        3          0    (1, 0)           0            1.336628   \n",
       "40         1        3          0    (1, 0)           0            1.336628   \n",
       "46         1        3          0    (1, 0)           0            1.336628   \n",
       "56         0        3          0   (1, -1)           0            1.336628   \n",
       "57         0        3          0   (1, -1)           0            1.336628   \n",
       "64         1        3          0   (1, -1)           0            1.336628   \n",
       "70         1        3          0   (1, -1)           0            1.336628   \n",
       "80         0        3          0    (0, 0)           1            1.411163   \n",
       "81         0        3          0    (0, 0)           1            1.411163   \n",
       "88         1        3          0    (0, 0)           1            1.411163   \n",
       "94         1        3          0    (0, 0)           1            1.411163   \n",
       "104        0        3          0    (1, 0)           1            1.411163   \n",
       "105        0        3          0    (1, 0)           1            1.411163   \n",
       "112        1        3          0    (1, 0)           1            1.411163   \n",
       "118        1        3          0    (1, 0)           1            1.411163   \n",
       "128        0        3          0   (1, -1)           1            1.411163   \n",
       "129        0        3          0   (1, -1)           1            1.411163   \n",
       "136        1        3          0   (1, -1)           1            1.411163   \n",
       "142        1        3          0   (1, -1)           1            1.411163   \n",
       "152        0        3          0    (0, 0)           2            1.482761   \n",
       "153        0        3          0    (0, 0)           2            1.482761   \n",
       "160        1        3          0    (0, 0)           2            1.482761   \n",
       "166        1        3          0    (0, 0)           2            1.482761   \n",
       "176        0        3          0    (1, 0)           2            1.482761   \n",
       "177        0        3          0    (1, 0)           2            1.482761   \n",
       "184        1        3          0    (1, 0)           2            1.482761   \n",
       "190        1        3          0    (1, 0)           2            1.482761   \n",
       "200        0        3          0   (1, -1)           2            1.482761   \n",
       "201        0        3          0   (1, -1)           2            1.482761   \n",
       "208        1        3          0   (1, -1)           2            1.482761   \n",
       "214        1        3          0   (1, -1)           2            1.482761   \n",
       "224        0        3          0    (0, 0)           3            1.623678   \n",
       "225        0        3          0    (0, 0)           3            1.623678   \n",
       "232        1        3          0    (0, 0)           3            1.623678   \n",
       "238        1        3          0    (0, 0)           3            1.623678   \n",
       "248        0        3          0    (1, 0)           3            1.623678   \n",
       "249        0        3          0    (1, 0)           3            1.623678   \n",
       "256        1        3          0    (1, 0)           3            1.623678   \n",
       "262        1        3          0    (1, 0)           3            1.623678   \n",
       "272        0        3          0   (1, -1)           3            1.623678   \n",
       "273        0        3          0   (1, -1)           3            1.623678   \n",
       "280        1        3          0   (1, -1)           3            1.623678   \n",
       "286        1        3          0   (1, -1)           3            1.623678   \n",
       "\n",
       "     simplestratification  stratifiedCohenMeasure  weighted_regression_result  \n",
       "8                1.321314                1.370916                    1.320065  \n",
       "9                1.321314                1.347950                    1.356843  \n",
       "16               1.321314                1.343842                    1.289228  \n",
       "22               1.321314                1.359434                    1.350109  \n",
       "32               1.395899                1.477489                    1.455792  \n",
       "33               1.395899                1.427997                    1.452227  \n",
       "40               1.395899                1.440211                    1.285218  \n",
       "46               1.395899                1.423167                    1.354170  \n",
       "56               0.639603                1.505094                    1.400228  \n",
       "57               0.639603                1.558843                    1.442988  \n",
       "64               0.639603                1.533595                    1.277198  \n",
       "70               0.639603                1.515472                    1.362293  \n",
       "80               1.399825                1.414415                    1.557265  \n",
       "81               1.399825                1.417067                    1.619656  \n",
       "88               1.399825                1.415144                    1.592494  \n",
       "94               1.399825                1.414948                    1.632260  \n",
       "104              1.466441                1.498874                    1.580835  \n",
       "105              1.466441                1.508884                    1.625116  \n",
       "112              1.466441                1.492401                    1.562167  \n",
       "118              1.466441                1.521657                    1.601370  \n",
       "128              1.042302                1.499018                    1.583942  \n",
       "129              1.042302                1.408639                    1.673126  \n",
       "136              1.042302                1.505946                    1.501512  \n",
       "142              1.042302                1.423491                    1.539589  \n",
       "152              1.539365                1.529771                    1.527525  \n",
       "153              1.539365                1.489039                    1.585735  \n",
       "160              1.539365                1.524554                    1.512944  \n",
       "166              1.539365                1.488523                    1.590797  \n",
       "176              1.408741                1.463583                    1.477929  \n",
       "177              1.408741                1.490117                    1.556242  \n",
       "184              1.408741                1.459808                    1.538155  \n",
       "190              1.408741                1.482492                    1.625100  \n",
       "200              0.839380                1.545617                    1.091733  \n",
       "201              0.839380                1.608715                    1.143697  \n",
       "208              0.839380                1.577588                    1.588576  \n",
       "214              0.839380                1.540309                    1.693706  \n",
       "224              1.698905                1.702194                    1.864823  \n",
       "225              1.698905                1.675271                    1.936530  \n",
       "232              1.698905                1.694244                    1.788767  \n",
       "238              1.698905                1.677443                    1.879119  \n",
       "248              1.319703                1.619284                    1.749312  \n",
       "249              1.319703                1.530940                    1.773162  \n",
       "256              1.319703                1.623710                    1.811306  \n",
       "262              1.319703                1.527642                    1.902721  \n",
       "272              0.967877                1.636683                    1.432312  \n",
       "273              0.967877                1.607365                    1.441657  \n",
       "280              0.967877                1.636124                    1.856383  \n",
       "286              0.967877                1.607407                    1.949924  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[(tmp.Control == 3)&(tmp.Treatment == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "c950887b79b21"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "comet_cell_id": "b6372e39eb132"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear_regression_result</th>\n",
       "      <th>weighted_regression_result</th>\n",
       "      <th>simpleCohenMeasure</th>\n",
       "      <th>simplestratification</th>\n",
       "      <th>stratifiedCohenMeasure</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1.348091</td>\n",
       "      <td>1.393301</td>\n",
       "      <td>1.412611</td>\n",
       "      <td>1.406305</td>\n",
       "      <td>1.432053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>1.405564</td>\n",
       "      <td>1.466006</td>\n",
       "      <td>1.467262</td>\n",
       "      <td>1.491562</td>\n",
       "      <td>1.491335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>1.409116</td>\n",
       "      <td>1.477580</td>\n",
       "      <td>1.474114</td>\n",
       "      <td>1.493984</td>\n",
       "      <td>1.496227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>1.449706</td>\n",
       "      <td>1.518674</td>\n",
       "      <td>1.502679</td>\n",
       "      <td>1.526781</td>\n",
       "      <td>1.534849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>1.439679</td>\n",
       "      <td>1.513157</td>\n",
       "      <td>1.504900</td>\n",
       "      <td>1.534952</td>\n",
       "      <td>1.537213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       linear_regression_result  weighted_regression_result  \\\n",
       "N                                                             \n",
       "1000                   1.348091                    1.393301   \n",
       "3000                   1.405564                    1.466006   \n",
       "5000                   1.409116                    1.477580   \n",
       "10000                  1.449706                    1.518674   \n",
       "20000                  1.439679                    1.513157   \n",
       "\n",
       "       simpleCohenMeasure  simplestratification  stratifiedCohenMeasure  \n",
       "N                                                                        \n",
       "1000             1.412611              1.406305                1.432053  \n",
       "3000             1.467262              1.491562                1.491335  \n",
       "5000             1.474114              1.493984                1.496227  \n",
       "10000            1.502679              1.526781                1.534849  \n",
       "20000            1.504900              1.534952                1.537213  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaltest[(finaltest.Control == 3)&(finaltest.Treatment == 0)].groupby('N').mean()[['linear_regression_result','weighted_regression_result','simpleCohenMeasure','simplestratification','stratifiedCohenMeasure']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "6456b0f4039f6"
   },
   "outputs": [],
   "source": [
    "#TODO for simulation\n",
    "#Run 1000 iterations of sample sizes 1000, 5000, 10000, 30000, 50000\n",
    "#Run linear regression to get coefficient (for each group comparison)\n",
    "#Average all coefficients (across the 1000 iterations) to get true value\n",
    "\n",
    "#Compare proportion change because actual value group mean differences change when proportion changes (it's my hypothesis)\n",
    "#Once tested, throw out proportion change\n",
    "\n",
    "#Run 1000 iterations on supercomputer with everything (try to distribute as much as possible)\n",
    "#Plug in true values for bias equations\n",
    "#Analyze with your analysis script and meet with Ross to make sure everything looks ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "8259fbb38f7c9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "bc5cd6bbba206"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "comet_paths": [],
  "comet_tracking": true,
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
