{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "8ae43480f65ad"
   },
   "outputs": [],
   "source": [
    "#IMPORT NECESSARY MODULES\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "#CHANGE DISPLAY OPTIONS TO SHOW MORE ROWS AND COLUMNS\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "#LIST OF ALL JOURNALS AND THEIR GROUPS\n",
    "online_journals = [\n",
    "    ['American Journal of Distance Education','0892-3647'],\n",
    "    ['Distance Education','0158-7919'],\n",
    "    ['E-Learning','1741-8887'],\n",
    "    ['Electronic Journal of e-Learning','1479-4403'],\n",
    "    ['International Journal of Distance Education Technologies','1539-3100'],\n",
    "    ['International Review of Research in Open and Distance Learning','1492-3831'],\n",
    "    ['International Journal of Mobile and Blended Learning','1941-8647'],\n",
    "    ['Journal of Educators Online','1547-500X'],\n",
    "    ['Journal of E-Learning and Knowledge Society','1826-6223'],\n",
    "    ['Journal of Library and Information Services in Distance Learning','1533-290X'],\n",
    "    ['Journal of Interactive Online Learning','1541-4914'],\n",
    "    ['Open Learning','0268-0513'],\n",
    "    ['Turkish Online Journal of Distance Education','1302-6488'],\n",
    "]\n",
    "\n",
    "ed_tech_journals = [\n",
    "    ['Australasian Journal of Educational Technology','1449-5554'],\n",
    "    ['British Journal of Educational Technology','0007-1013'],\n",
    "    ['Bulletin of the Technical Committee on Learning Technology','2306-0212'],\n",
    "    ['Computer Assisted Language Learning','0958-8221'],\n",
    "    ['Computers and Education','0360-1315'],\n",
    "    ['Computers in Education Journal','1069-3769'],\n",
    "    ['Computers in the Schools','0738-0569'],\n",
    "    ['Cutting-Edge Technologies in Higher Education','2044-9968'],\n",
    "    ['DESIDOC Journal of Library and Information Technology','0974-0643'],\n",
    "    ['Education and Information Technologies','1360-2357'],\n",
    "    ['Educational Communication and Technology Journal','0148-5806'],\n",
    "    ['Educational Media International','0952-3987'],\n",
    "    ['Educational Technology and Society','1436-4522'],\n",
    "    ['Educational Technology Research and Development','1042-1629'],\n",
    "    ['Interactive Learning Environments','1049-4820'],\n",
    "    ['Interactive Technology and Smart Education','1741-5659'],\n",
    "    ['International Journal of Computer Supported Collaborative Learning','1556-1607'],\n",
    "    ['International Journal of Educational Technology in Higher Education','EISSN: 2365-9440'],\n",
    "    ['International Journal of Information and Communication Technology Education','1550-1876'],\n",
    "    ['International Journal of Information and Learning Technology','2056-4880'],\n",
    "    ['International Journal of Innovation and Learning','1471-8197'],\n",
    "    ['International Journal of Learning Technology','1477-8386'],\n",
    "    ['International Journal of Technologies in Learning','2327-0144'],\n",
    "    ['International Journal of Technology and Design Education','0957-7572'],\n",
    "    ['International Journal of Technology Enhanced Learning','1753-5255'],\n",
    "    ['International Journal of Web-Based Learning and Teaching Technologies','1548-1093'],\n",
    "    ['Internet and Higher Education','1096-7516'],\n",
    "    ['Journal of Computer-Assisted Learning','0266-4909'],\n",
    "    ['Journal of Computing in Higher Education','1042-1726'],\n",
    "    ['Journal of Educational Computing Research','0735-6331'],\n",
    "    ['Journal of Educational Multimedia and Hypermedia','1055-8896'],\n",
    "    ['Journal of Interactive Learning Research','1093-023X'],\n",
    "    ['Journal of Research on Technology in Education','1539-1523'],\n",
    "    ['Journal of Technology, Learning, and Assessment','1540-2525'],\n",
    "    ['Knowledge Management and E-Learning','2073-7904'],\n",
    "    ['Language, Learning, & Technology','1094-3501'],\n",
    "    ['Learning, Media and Technology','1743-9884'],\n",
    "    ['Performance Improvement Quarterly','0898-5952'],\n",
    "    ['Research in Learning Technology','2156-7069'],\n",
    "    ['Technology, Knowledge and Learning','2211-1662'],\n",
    "    ['Technology, Pedagogy and Education','1475-939X'],\n",
    "    ['TechTrends','8756-3894'],\n",
    "    ['Turkish Online Journal of Educational Technology','1303-6521']\n",
    "]\n",
    "    \n",
    "education_journals = [\n",
    "    ['Cognition and Instruction','0737-0008'],\n",
    "    ['International Journal of Instruction','1694-609X'],\n",
    "    ['International Journal of Knowledge and Learning','1741-1009'],\n",
    "    ['International Journal of Learning','1447-9494'],\n",
    "    ['Instructional Science','0020-4277'],\n",
    "    ['Journal of Learning Sciences','1050-8406'],\n",
    "    ['Learning and Instruction','0959-4752'],\n",
    "    ['Learning Environments Research','1387-1579'],\n",
    "    ['Memory and Cognition','0090-502X'],\n",
    "]\n",
    "\n",
    "computer_science_journals = [\n",
    "    ['International Journal of Mobile Human Computer Interaction','1942-390X'],\n",
    "    ['International Journal of Technology and Human Interaction','1548-3908'],\n",
    "    ['International Journal of Artificial Intelligence in Education','1560-4292'],\n",
    "    ['Australian Educational Computing','0816-9020'],\n",
    "    ['Computers in Human Behavior','0747-5632'],\n",
    "    ['Human-Computer Interaction','0737-0024'],\n",
    "    ['IEEE Transactions on Learning Technologies','1939-1382'],\n",
    "    ['Information Technology and Libraries','0730-9295'],\n",
    "    ['International Journal of Human Computer Studies','1071-5819'],\n",
    "    ['International Journal of Human-Computer Interaction','1044-7318'],\n",
    "    ['Journal of Computer-Mediated Communication','1083-6101'],\n",
    "]\n",
    "#READ ALL DATA AND APPEND TO NEW DATAFRAME\n",
    "import os\n",
    "base = 'C:/Users/bodil/Projects/Rick Journal Data/'\n",
    "df = pd.DataFrame()\n",
    "for file_name in os.listdir(base + 'Data/'):\n",
    "    df2 = pd.read_csv(base + 'Data/' + file_name, low_memory=False)\n",
    "    df2['journal'] = file_name.split('.')[0]\n",
    "    df = df.append(df2)\n",
    "df = df[df.articleType == 'Article'].copy()\n",
    "df = df[df.abstract == df.abstract].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "789907a0341a4"
   },
   "outputs": [],
   "source": [
    "def parse_abstract(cell):\n",
    "    cell_list = cell.split('.')\n",
    "    first_sentence = '©' in cell_list[0] or 'Taylor & Francis' in cell_list [0] or 'All rights reserved' in cell_list[0] or \\\n",
    "    ' LLC.' in cell_list[0] or 'Elsevier' in cell_list[0] or 'Springer' in cell_list[0]\n",
    "    second_sentence = 'All rights reserved' in cell_list[1]\n",
    "    last_sentence = '©' in cell_list[-1] or 'Taylor & Francis' in cell_list [-1] or 'All rights reserved' in cell_list[-1] or \\\n",
    "    ' LLC.' in cell_list[-1] or 'Elsevier' in cell_list[-1] or 'Springer' in cell_list[-1]\n",
    "    if second_sentence and last_sentence:\n",
    "        return '.'.join(cell_list[2:-1])\n",
    "    elif second_sentence and not last_sentence:\n",
    "        return '.'.join(cell_list[2:])\n",
    "    elif first_sentence and last_sentence:\n",
    "        return '.'.join(cell_list[1:-1])\n",
    "    elif first_sentence and not last_sentence:\n",
    "        return '.'.join(cell_list[1:])\n",
    "    elif not first_sentence and last_sentence:\n",
    "        return '.'.join(cell_list[:-1])\n",
    "    else:\n",
    "        return '.'.join(cell_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "0d76625f8bc1e"
   },
   "outputs": [],
   "source": [
    "df['new_abstract'] = df.abstract.map(parse_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "53f32c987ed38"
   },
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "34d9fb18fab85"
   },
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "df['sentence_abstract_list'] = df['new_abstract'].map(lambda x: tokenize.sent_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "f67d3d32f844f"
   },
   "outputs": [],
   "source": [
    "tempdf = df[['sentence_abstract_list']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "e35bdc6b5a3b4"
   },
   "outputs": [],
   "source": [
    "finaldf = pd.DataFrame({\n",
    "    col:np.repeat(tempdf[col].values, tempdf['sentence_abstract_list'].str.len())\n",
    "    for col in tempdf.columns.difference(['sentence_abstract_list'])\n",
    "    }).assign(**{'sentence_abstract_list':np.concatenate(tempdf['sentence_abstract_list'].values)})[tempdf.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "8d3ac86c86b5a"
   },
   "outputs": [],
   "source": [
    "finaldf['sentence_abstract_series_of_lists_of_words'] = finaldf['sentence_abstract_list'].map(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "f3b14b0fa0a9c"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "translator = str.maketrans('','',string.punctuation + '’')\n",
    "def remove_punctuation(cell):\n",
    "    word_list = []\n",
    "    for word in cell:\n",
    "        word = word.translate(translator)\n",
    "        if word == ' ' or word == '':\n",
    "            pass\n",
    "        else:\n",
    "            word_list.append(word.lower())\n",
    "    return word_list\n",
    "\n",
    "finaldf['sentence_abstract_series_of_lists_of_words'] = finaldf['sentence_abstract_series_of_lists_of_words'].map(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "b8f1a649347dc"
   },
   "outputs": [],
   "source": [
    "sentences = finaldf.sentence_abstract_series_of_lists_of_words.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "dfa321d066f48"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "caae93c75c112"
   },
   "outputs": [],
   "source": [
    "phrases = Phrases(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "6bb9493d970cc"
   },
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phraser\n",
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "d00b0588e9c9e"
   },
   "outputs": [],
   "source": [
    "finaldf['bigram_sentences'] = finaldf.sentence_abstract_series_of_lists_of_words.map(lambda x: bigram[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "14494f8ebe856"
   },
   "outputs": [],
   "source": [
    "sentences = finaldf.bigram_sentences.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "comet_cell_id": "a7f8c00583262"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sentences\n",
      "334312\n"
     ]
    }
   ],
   "source": [
    "print('number of sentences')\n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "7ffa1e9027f85"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "finaldf['length'] = finaldf['bigram_sentences'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "comet_cell_id": "99a1e208207c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f57a547438>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMRwkSRXDQZJU+f/Wj7XMXebVKQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f5c20a0d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finaldf[finaldf['length'] < 70]['length'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "d6c0815dde874"
   },
   "outputs": [],
   "source": [
    "def compute_training_examples(cell):\n",
    "    if cell < 12:\n",
    "        return 1\n",
    "    else:\n",
    "        return cell - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "comet_cell_id": "661a4efb3c961"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples for your sentences\n",
      "3720035\n"
     ]
    }
   ],
   "source": [
    "print('number of training examples for your sentences')\n",
    "print(finaldf['length'].map(compute_training_examples).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "d76fe2134d239"
   },
   "outputs": [],
   "source": [
    "# sentences is a list of sentences, each broken up into a list of words\n",
    "# sg {1, 0} - 1 = skip-gram, 0 = CBOW\n",
    "# size: dimensionality of the feature vectors\n",
    "# window: the maximum distance between the current and predicted word\n",
    "# alpha: the initial learning rate\n",
    "# min_alpha: learning rate will drop linearly to min_alpha throughout training\n",
    "# seed: for the random number generator (to get reproducible results, use seed, workers=1, and PYTHONHASHSEED environment variable)\n",
    "# min_count: ignores all words with total frequency lower than this\n",
    "# max_vocab_size: Limits the RAM during vocabulary building. 10M word types needs 1 GB of RAM\n",
    "# sample: the threshold for configuring which higher-frequency words are randomly downsampled\n",
    "# workers: faster training with multicore machines\n",
    "# hs {1, 0} 1 = hierarchical softmax, 0 = (if negative = 0) negative sampling\n",
    "# negative: If greater than 0, negative sampling will be used, specifies how many \"noise words\" should be drawn. \n",
    "# cbow_mean: If 0 use sum of context word vectors. If 1, use the mean (when CBOW is used only)\n",
    "# hashfxn to use to increase training reproducibility\n",
    "# iter: number of iterations over corpus\n",
    "# trim_rule\n",
    "# sorted_vocab: 1, 0 -> sort vocab by descending frequency before assigning word indexes\n",
    "# batch_words: target word size for batches of examples passed to workers\n",
    "# compute_loss: If true, computes and stores loss value which can be retrieved using model.get_latest_training_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "ac43d0e7ddc28"
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences, size=300, window=5, min_count=5, workers=4, compute_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "e7252227d9adc"
   },
   "outputs": [],
   "source": [
    "fname = 'C:/Users/bodil/Projects/NLP/word2vec_two_word_phrase_model'\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true,
    "comet_cell_id": "8f5722281fd7b"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "model = Word2Vec.load(fname)  # you can continue training with the loaded model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "comet_cell_id": "610e338b17889"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11174136.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_latest_training_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "comet_cell_id": "20702c749d4a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('archer', 0.8701130747795105),\n",
       " ('moore', 0.865913450717926),\n",
       " ('siegler', 0.8490069508552551),\n",
       " ('pintrich', 0.8482726812362671),\n",
       " ('howard', 0.8471344113349915),\n",
       " ('kern', 0.8459733128547668),\n",
       " ('warschauer', 0.8419070243835449),\n",
       " ('kim', 0.8413731455802917),\n",
       " ('garrison', 0.8408752679824829),\n",
       " ('bjork', 0.8407337665557861)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#worst case scenario, 5 levels deep using random word from top 10 still gives me good results.\n",
    "#best case scenario, 10 levels deep using random word from top 10 still gives me good results.\n",
    "model.wv.most_similar('bandura',topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "comet_cell_id": "e6e30904a641e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('achievements', 0.45201337337493896),\n",
       " ('achievement', 0.4296368658542633),\n",
       " ('involvement', 0.4219371974468231),\n",
       " ('retention', 0.40923577547073364),\n",
       " ('engagement', 0.4060382544994354),\n",
       " ('satisfaction', 0.40450966358184814),\n",
       " ('overall', 0.3979598581790924),\n",
       " ('academic_performance', 0.39729389548301697),\n",
       " ('performances', 0.3934357762336731),\n",
       " ('academic_achievement', 0.3754035532474518)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.wv.most_similar(positive=['technology', 'computer'], negative=['computer'])\n",
    "model.wv.most_similar(positive=['self_regulation','motivation'], negative=['zimmerman','bandura'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "comet_cell_id": "fc40dabc1c649"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67267032239107105"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('engagement', 'motivation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "comet_cell_id": "b367dcf136b5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'teacher'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"creativity self-regulation motivation teacher\".split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "comet_cell_id": "7c9ea81cebf9d"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "We have currently only implemented score for the hierarchical softmax scheme, so you need to have run word2vec with hs=1 and negative=0 for this to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-8e8487d5922d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"The fox jumped over a lazy dog\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\bodil\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, sentences, total_sentences, chunksize, queue_factor, report_delay)\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m             raise RuntimeError(\n\u001b[1;32m--> 666\u001b[1;33m                 \u001b[1;34m\"We have currently only implemented score for the hierarchical softmax scheme, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    667\u001b[0m                 \u001b[1;34m\"so you need to have run word2vec with hs=1 and negative=0 for this to work.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m             )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: We have currently only implemented score for the hierarchical softmax scheme, so you need to have run word2vec with hs=1 and negative=0 for this to work."
     ]
    }
   ],
   "source": [
    "model.score([\"The fox jumped over a lazy dog\".split()])"
   ]
  }
 ],
 "metadata": {
  "comet_paths": [
   [
    "0a21c2a4\\word2vec.ipynb",
    1527169443022
   ],
   [
    "0a21c2a4\\word2vec_single_word_model-Copy1.ipynb",
    1527286065014
   ],
   [
    "0a21c2a4\\word2vec_phrase_model.ipynb",
    1527286290586
   ],
   [
    "0a21c2a4\\word2vec_two_word_phrase_model.ipynb",
    1527304973917
   ]
  ],
  "comet_tracking": true,
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
